<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Zookeeper集群搭建测试]]></title>
    <url>%2F2019%2F08%2F26%2FZookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[单台机器搭建一个伪Zookeeper集群，用于测试学习。 节点 主机 客户端连接端口 follower连接leader端口 leader选举端口 server.1 192.168.91.146 2181 2887 3887 server.2 192.168.91.146 2182 2888 3888 server.3 192.168.91.146 2183 2889 3889 准备目录1234567[root@pseudo-cluster zookeeper-cluster-test]# ls -lhtotal 8.0K-rwxr-xr-x. 1 root root 147 Aug 23 11:03 shutdown.sh-rwxr-xr-x. 1 root root 265 Aug 23 10:53 startup.shdrwxr-xr-x. 8 root root 166 Aug 22 16:58 zookeeper-3.5.5-server.1drwxr-xr-x. 8 root root 166 Aug 22 17:26 zookeeper-3.5.5-server.2drwxr-xr-x. 8 root root 166 Aug 22 17:26 zookeeper-3.5.5-server.3 修改配置文件分别修改server.1、server.2、server.3三个节点的conf/zoo.cfg配置文件 12345678910111213141516171819# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=5# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=2# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=__DATA_ZOO__/datadataLogDir=__DATA_ZOO__/logs# the port at which the clients will connectclientPort=2181# server.x=[hostname]:nnnnn[:nnnnn], etc : (No Java system property) servers making up the ZooKeeper ensemble. When the server starts up, it determines which server it is by looking for the file myid in the data directory. That file contains the server number, in ASCII, and it should match x in server.x in the left hand side of this setting. The list of servers that make up ZooKeeper servers that is used by the clients must match the list of ZooKeeper servers that each ZooKeeper server has. There are two port numbers nnnnn. The first followers use to connect to the leader, and the second is for leader election. If you want to test multiple servers on a single machine, then different ports can be used for each server.server.1=192.168.91.146:2887:3887server.2=192.168.91.146:2888:3888server.3=192.168.91.146:2889:3889 123456789tickTime=2000initLimit=5syncLimit=2dataDir=__DATA_ZOO__/datadataLogDir=__DATA_ZOO__/logsclientPort=2182server.1=192.168.91.146:2887:3887server.2=192.168.91.146:2888:3888server.3=192.168.91.146:2889:3889 123456789tickTime=2000initLimit=5syncLimit=2dataDir=__DATA_ZOO__/datadataLogDir=__DATA_ZOO__/logsclientPort=2183server.1=192.168.91.146:2887:3887server.2=192.168.91.146:2888:3888server.3=192.168.91.146:2889:3889 启停脚本启动脚本1234567891011#!/usr/bin/env bashcurrent_path=`pwd`nodes=(zookeeper-3.5.5-server.1 zookeeper-3.5.5-server.2 zookeeper-3.5.5-server.3)for val in "$&#123;nodes[@]&#125;"do path=$current_path/$val echo $path cd $path ./bin/zkServer.sh startdonejps -l | grep QuorumPeerMain 启动12345678910111213141516171819[root@pseudo-cluster zookeeper-cluster-test]# pwd/usr/local/zookeeper-cluster-test[root@pseudo-cluster zookeeper-cluster-test]# ./startup.sh /usr/local/zookeeper-cluster-test/zookeeper-3.5.5-server.1ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster-test/zookeeper-3.5.5-server.1/bin/../conf/zoo.cfgStarting zookeeper ... STARTED/usr/local/zookeeper-cluster-test/zookeeper-3.5.5-server.2ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster-test/zookeeper-3.5.5-server.2/bin/../conf/zoo.cfgStarting zookeeper ... STARTED/usr/local/zookeeper-cluster-test/zookeeper-3.5.5-server.3ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster-test/zookeeper-3.5.5-server.3/bin/../conf/zoo.cfgStarting zookeeper ... STARTED56626 org.apache.zookeeper.server.quorum.QuorumPeerMain56739 org.apache.zookeeper.server.quorum.QuorumPeerMain56679 org.apache.zookeeper.server.quorum.QuorumPeerMain[root@pseudo-cluster zookeeper-cluster-test]# 查看集群停止脚本12345#!/usr/bin/env bashjps -l | grep QuorumPeerMainkill -9 $(jps -l | grep org.apache.zookeeper.server.quorum.QuorumPeerMain | awk '&#123;&#123;print $1&#125;&#125;') 停止1234[root@pseudo-cluster zookeeper-cluster-test]# ./shutdown.sh 56626 org.apache.zookeeper.server.quorum.QuorumPeerMain56739 org.apache.zookeeper.server.quorum.QuorumPeerMain56679 org.apache.zookeeper.server.quorum.QuorumPeerMain]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The lifetime of a thread]]></title>
    <url>%2F2019%2F08%2F22%2FThe%20lifetime%20of%20a%20thread%2F</url>
    <content type="text"><![CDATA[The lifetime of a thread线程的状态线程有六种状态，定义在java.lang.Thread.State内部枚举中： 12345678public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; A thread state. A thread can be in one of the following states: NEW A thread that has not yet started is in this state. RUNNABLE A thread executing in the Java virtual machine is in this state. BLOCKED A thread that is blocked waiting for a monitor lock is in this state. 处于此状态，线程被阻塞等待监视器锁 WAITING A thread that is waiting indefinitely for another thread to perform a particular action is in this state. 无限期等待另外线程执行特定的动作，通常为唤醒等操作 TIMED_WAITING A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state. 限期等待 TERMINATED A thread that has exited is in this state. A thread can be in only one state at a given point in time. These states are virtual machine states which do not reflect any operating system thread states. 线程的生命周期实现三个线程，其中Thread-01执行睡眠，Thread-02、Thread-03执行同步任务，jstack抓取堆栈信息，观察线程状态。123456789101112131415161718192021222324252627282930313233343536373839404142public static void main(String[] args) &#123; Thread thd01 = new Thread( () -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(120); &#125; catch (InterruptedException e) &#123; // ignore &#125; &#125;, "Thread-01"); Thread thd02 = new Thread( () -&gt; &#123; doSorting(); &#125;, "Thread-02"); Thread thd03 = new Thread( () -&gt; &#123; doSorting(); &#125;, "Thread-03"); thd01.start(); thd02.start(); thd03.start();&#125;public static synchronized void doSorting() &#123; for (; ; ) &#123; // 生成随机数组 double[] a = new double[100]; for (int i = 0; i &lt; a.length; i++) &#123; a[i] = new Random().nextDouble(); &#125; // 对随机数组进行排序，使其消耗CPU Arrays.sort(a); &#125;&#125; 如堆栈信息所示，Thread-01处于TIMED_WAITING状态，Thread-02处于RUNNABLE状态，Thread-02处于BLOCKED状态。123456789101112131415161718192021222324252627282930313233&quot;Thread-03&quot; #13 prio=5 os_prio=0 tid=0x000000002092b000 nid=0x345c waiting for monitor entry [0x00000000214fe000] java.lang.Thread.State: BLOCKED (on object monitor) at io.mysnippet.multithread.ThreadState.doSorting(ThreadState.java:49) - waiting to lock &lt;0x000000068280a830&gt; (a java.lang.Class for io.mysnippet.multithread.ThreadState) at io.mysnippet.multithread.ThreadState.lambda$main$2(ThreadState.java:37) at io.mysnippet.multithread.ThreadState$$Lambda$3/1078694789.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None&quot;Thread-02&quot; #12 prio=5 os_prio=0 tid=0x000000002092a000 nid=0x748 runnable [0x00000000213fe000] java.lang.Thread.State: RUNNABLE at io.mysnippet.multithread.ThreadState.doSorting(ThreadState.java:50) - locked &lt;0x000000068280a830&gt; (a java.lang.Class for io.mysnippet.multithread.ThreadState) at io.mysnippet.multithread.ThreadState.lambda$main$1(ThreadState.java:30) at io.mysnippet.multithread.ThreadState$$Lambda$2/1096979270.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None&quot;Thread-01&quot; #11 prio=5 os_prio=0 tid=0x0000000020949800 nid=0x4494 waiting on condition [0x00000000212ff000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at io.mysnippet.multithread.ThreadState.lambda$main$0(ThreadState.java:20) at io.mysnippet.multithread.ThreadState$$Lambda$1/2003749087.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None]]></content>
      <categories>
        <category>thread</category>
      </categories>
      <tags>
        <tag>thread</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch集群搭建测试]]></title>
    <url>%2F2019%2F08%2F21%2FElasticsearch%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[单台机器搭建一个伪Elasticsearch集群，用于测试学习。 节点 主机 HTTP端口 TCP端口 node-0 192.168.91.146 9200 9300 node-1 192.168.91.146 9201 9301 node-2 192.168.91.146 9202 9302 准备目录下载elasticsearch安装包，按照如下目录组织 12345678910[root@pseudo-cluster es-cluser-test]# pwd/usr/local/es-cluser-test[root@pseudo-cluster es-cluser-test]# ls -lhtotal 8.0Kdrwxr-xr-x. 9 elasticsearch elasticsearch 155 Aug 11 03:22 es-6.6.2-node0drwxr-xr-x. 9 elasticsearch elasticsearch 165 Aug 11 03:22 es-6.6.2-node1drwxr-xr-x. 9 elasticsearch elasticsearch 155 Aug 11 03:22 es-6.6.2-node2-rwxr-xr-x. 1 elasticsearch elasticsearch 253 Aug 9 03:07 shutdown.sh-rwxr-xr-x. 1 elasticsearch elasticsearch 264 Aug 9 03:13 startup.sh[root@pseudo-cluster es-cluser-test]# 添加用户&amp;组&amp;赋权123[root@pseudo-cluster es-cluser-test]# groupadd elasticsearch[root@pseudo-cluster es-cluser-test]# useradd elasticsearch -g elasticsearch[root@pseudo-cluster es-cluser-test]# chown -R elasticsearch.elasticsearch /usr/local/es-cluser-test 修改配置文件分别修改node0、node1、node2三个节点的config/elasticsearch.yml配置文件 12345678cluster.name: es-pseudo-clusternode.name: node-0bootstrap.memory_lock: truenetwork.host: 192.168.91.146http.port: 9200transport.tcp.port: 9300discovery.zen.ping.unicast.hosts: ["192.168.91.146:9301", "192.168.91.146:9302"]discovery.zen.minimum_master_nodes: 2 12345678cluster.name: es-pseudo-clusternode.name: node-1bootstrap.memory_lock: truenetwork.host: 192.168.91.146http.port: 9201transport.tcp.port: 9301discovery.zen.ping.unicast.hosts: ["192.168.91.146:9300", "192.168.91.146:9302"]discovery.zen.minimum_master_nodes: 2 12345678cluster.name: es-pseudo-clusternode.name: node-2bootstrap.memory_lock: truenetwork.host: 192.168.91.146http.port: 9202transport.tcp.port: 9302discovery.zen.ping.unicast.hosts: ["192.168.91.146:9300", "192.168.91.146:9301"]discovery.zen.minimum_master_nodes: 2 启停脚本启动脚本1234567891011121314#!/usr/bin/env bashcurrent_path=`pwd`nodes=(es-6.6.2-node0 es-6.6.2-node1 es-6.6.2-node2)for val in "$&#123;nodes[@]&#125;"do path=$current_path/$val echo $path cd $path ./bin/elasticsearch -d -p piddoneps -elf | grep -v 'grep' | grep Elasticsearch 启动12345678910111213141516171819[root@pseudo-cluster es-cluser-test]# pwd/usr/local/es-cluser-test[root@pseudo-cluster es-cluser-test]# ls -lhtotal 8.0Kdrwxr-xr-x. 9 elasticsearch elasticsearch 155 Aug 14 03:52 es-6.6.2-node0drwxr-xr-x. 9 elasticsearch elasticsearch 155 Aug 14 03:56 es-6.6.2-node1drwxr-xr-x. 9 elasticsearch elasticsearch 155 Aug 14 03:56 es-6.6.2-node2-rwxr-xr-x. 1 elasticsearch elasticsearch 253 Aug 9 03:07 shutdown.sh-rwxr-xr-x. 1 elasticsearch elasticsearch 264 Aug 14 03:55 startup.sh[root@pseudo-cluster es-cluser-test]# [root@pseudo-cluster es-cluser-test]# su elasticsearch[elasticsearch@pseudo-cluster es-cluser-test]$ ./startup.sh /usr/local/es-cluser-test/es-6.6.2-node0/usr/local/es-cluser-test/es-6.6.2-node1/usr/local/es-cluser-test/es-6.6.2-node20 S elastic+ 30162 1 99 80 0 - 776807 futex_ 03:57 pts/0 00:00:01 /usr/local/jdk1.8.0_221/bin/java -Xms512m -Xmx512m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.io.tmpdir=/tmp/elasticsearch-3768772128440104570 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -Xloggc:logs/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=32 -XX:GCLogFileSize=64m -Des.path.home=/usr/local/es-cluser-test/es-6.6.2-node0 -Des.path.conf=/usr/local/es-cluser-test/es-6.6.2-node0/config -Des.distribution.flavor=default -Des.distribution.type=tar -cp /usr/local/es-cluser-test/es-6.6.2-node0/lib/* org.elasticsearch.bootstrap.Elasticsearch -d -p pid0 S elastic+ 30238 1 0 80 0 - 773344 futex_ 03:57 pts/0 00:00:00 /usr/local/jdk1.8.0_221/bin/java -Xms512m -Xmx512m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.io.tmpdir=/tmp/elasticsearch-3776090600362042909 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -Xloggc:logs/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=32 -XX:GCLogFileSize=64m -Des.path.home=/usr/local/es-cluser-test/es-6.6.2-node1 -Des.path.conf=/usr/local/es-cluser-test/es-6.6.2-node1/config -Des.distribution.flavor=default -Des.distribution.type=tar -cp /usr/local/es-cluser-test/es-6.6.2-node1/lib/* org.elasticsearch.bootstrap.Elasticsearch -d -p pid0 S elastic+ 30314 1 0 80 0 - 25758 futex_ 03:57 pts/0 00:00:00 /usr/local/jdk1.8.0_221/bin/java -Xms512m -Xmx512m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.io.tmpdir=/tmp/elasticsearch-4360777951552716525 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -Xloggc:logs/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=32 -XX:GCLogFileSize=64m -Des.path.home=/usr/local/es-cluser-test/es-6.6.2-node2 -Des.path.conf=/usr/local/es-cluser-test/es-6.6.2-node2/config -Des.distribution.flavor=default -Des.distribution.type=tar -cp /usr/local/es-cluser-test/es-6.6.2-node2/lib/* org.elasticsearch.bootstrap.Elasticsearch -d -p pid[elasticsearch@pseudo-cluster es-cluser-test]$ 查看集群通过Elasticsearch Head查看集群 停止脚本1234567891011121314#!/usr/bin/env bashcurrent_path=`pwd`nodes=(es-6.6.2-node0 es-6.6.2-node1 es-6.6.2-node2)for val in "$&#123;nodes[@]&#125;"do path=$current_path/$val echo $path cd $path kill -9 `cat pid` doneps -elf | grep -v 'grep' | grep Elasticsearch 停止1234[elasticsearch@pseudo-cluster es-cluser-test]$ ./shutdown.sh /usr/local/es-cluser-test/es-6.6.2-node0/usr/local/es-cluser-test/es-6.6.2-node1/usr/local/es-cluser-test/es-6.6.2-node2]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 10 去除快捷方式小箭头]]></title>
    <url>%2F2019%2F08%2F10%2FWindows%2010%20%E5%8E%BB%E9%99%A4%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F%E5%B0%8F%E7%AE%AD%E5%A4%B4%2F</url>
    <content type="text"><![CDATA[Windows 10 去除快捷方式小箭头去掉小箭头123456reg add "HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Shell Icons" /v 29 /d "%systemroot%\system32\imageres.dll,197" /t reg_sz /ftaskkill /f /im explorer.exeattrib -s -r -h "%userprofile%\AppData\Local\iconcache.db"del "%userprofile%\AppData\Local\iconcache.db" /f /qstart explorerpause 恢复小箭头123456reg delete "HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Shell Icons" /v 29 /ftaskkill /f /im explorer.exeattrib -s -r -h "%userprofile%\AppData\Local\iconcache.db"del "%userprofile%\AppData\Local\iconcache.db" /f /qstart explorerpause]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis集群搭建测试]]></title>
    <url>%2F2019%2F08%2F01%2FRedis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[单台机器搭建一个伪Redis集群，用于测试学习。redis-3.2.13可以使用redis源码自行编译make prifix=/tmp/redis。 下载redis-cluster-test项目123456789[root@pseudo-cluster local]# pwd/usr/local[root@pseudo-cluster local]# git clone https://github.com/wyt/redis-cluster-test.git[root@pseudo-cluster bin]# pwd/usr/local/redis-cluster-test/redis-3.2.13/bin[root@pseudo-cluster bin]# chmod +x ./*[root@pseudo-cluster redis-cluster-test]# pwd/usr/local/redis-cluster-test[root@pseudo-cluster redis-cluster-test]# chmod +x shutdown.sh startup.sh 安装ruby环境等123456789101112# 安装ruby环境[root@pseudo-cluster redis-cluster-test] yum install centos-release-scl-rh[root@pseudo-cluster redis-cluster-test] yum install rh-ruby23 -y# 当前session生效[root@pseudo-cluster redis-cluster-test] scl enable rh-ruby23 bash[root@pseudo-cluster redis-cluster-test]# ruby -vruby 2.3.8p459 (2018-10-18 revision 65136) [x86_64-linux][root@pseudo-cluster redis-cluster-test]# gem install redisFetching: redis-4.1.2.gem (100%)Successfully installed redis-4.1.2Parsing documentation for redis-4.1.2Installing ri documentation for redis-4.1 规划集群1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@pseudo-cluster redis-cluster-test]# pwd/usr/local/redis-cluster-test[root@pseudo-cluster redis-cluster-test]# ls -lhtotal 16Kdrwxr-xr-x. 2 root root 64 Aug 1 18:57 7000drwxr-xr-x. 2 root root 64 Aug 1 18:57 7001drwxr-xr-x. 2 root root 64 Aug 1 18:57 7002drwxr-xr-x. 2 root root 64 Aug 1 18:57 7003drwxr-xr-x. 2 root root 64 Aug 1 18:57 7004drwxr-xr-x. 2 root root 64 Aug 1 18:57 7005-rw-r--r--. 1 root root 7.1K Aug 1 18:56 README.mddrwxr-xr-x. 3 root root 35 Aug 1 18:54 redis-3.2.13-rwxr-xr-x. 1 root root 75 Aug 1 18:54 shutdown.sh-rwxr-xr-x. 1 root root 635 Aug 1 18:54 startup.sh[root@pseudo-cluster redis-cluster-test]# ./startup.sh /usr/local/redis-cluster-test/7000/usr/local/redis-cluster-test/7001/usr/local/redis-cluster-test/7002/usr/local/redis-cluster-test/7003/usr/local/redis-cluster-test/7004/usr/local/redis-cluster-test/70055 S root 14845 1 0 80 0 - 35257 ep_pol 18:59 ? 00:00:00 ../redis-3.2.13/bin/redis-server *:7000 [cluster]5 S root 14849 1 0 80 0 - 35257 ep_pol 18:59 ? 00:00:00 ../redis-3.2.13/bin/redis-server *:7001 [cluster]5 S root 14853 1 0 80 0 - 35257 ep_pol 18:59 ? 00:00:00 ../redis-3.2.13/bin/redis-server *:7002 [cluster]5 S root 14857 1 0 80 0 - 35257 ep_pol 18:59 ? 00:00:00 ../redis-3.2.13/bin/redis-server *:7003 [cluster]5 S root 14861 1 0 80 0 - 35257 ep_pol 18:59 ? 00:00:00 ../redis-3.2.13/bin/redis-server *:7004 [cluster]5 S root 14865 1 0 80 0 - 35257 ep_pol 18:59 ? 00:00:00 ../redis-3.2.13/bin/redis-server *:7005 [cluster][root@pseudo-cluster redis-cluster-test]# ./redis-3.2.13/bin/redis-trib.rb create --replicas 1 192.168.91.146:7000 192.168.91.146:7001 192.168.91.146:7002 192.168.91.146:7003 192.168.91.146:7004 192.168.91.146:7005&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:192.168.91.146:7000192.168.91.146:7001192.168.91.146:7002Adding replica 192.168.91.146:7003 to 192.168.91.146:7000Adding replica 192.168.91.146:7004 to 192.168.91.146:7001Adding replica 192.168.91.146:7005 to 192.168.91.146:7002M: 50925d802a5f1be70521fafea196e8b112c122ca 192.168.91.146:7000 slots:0-5460 (5461 slots) masterM: c4a38513a633aab450a3d491c30ec6b305b7abef 192.168.91.146:7001 slots:5461-10922 (5462 slots) masterM: 963dd0cac7581f29464624cb0df8a678cdfc54cd 192.168.91.146:7002 slots:10923-16383 (5461 slots) masterS: 6f3aa71e0d754d54738d746bd617d31adabd0d3f 192.168.91.146:7003 replicates 50925d802a5f1be70521fafea196e8b112c122caS: 60cd05e9ed0350bd271fabacf00483bc9a34c2da 192.168.91.146:7004 replicates c4a38513a633aab450a3d491c30ec6b305b7abefS: 2755ff19dcb8d00967e66f7d19bf95603fa352dc 192.168.91.146:7005 replicates 963dd0cac7581f29464624cb0df8a678cdfc54cdCan I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join...&gt;&gt;&gt; Performing Cluster Check (using node 192.168.91.146:7000)M: 50925d802a5f1be70521fafea196e8b112c122ca 192.168.91.146:7000 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 963dd0cac7581f29464624cb0df8a678cdfc54cd 192.168.91.146:7002 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 2755ff19dcb8d00967e66f7d19bf95603fa352dc 192.168.91.146:7005 slots: (0 slots) slave replicates 963dd0cac7581f29464624cb0df8a678cdfc54cdM: c4a38513a633aab450a3d491c30ec6b305b7abef 192.168.91.146:7001 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 6f3aa71e0d754d54738d746bd617d31adabd0d3f 192.168.91.146:7003 slots: (0 slots) slave replicates 50925d802a5f1be70521fafea196e8b112c122caS: 60cd05e9ed0350bd271fabacf00483bc9a34c2da 192.168.91.146:7004 slots: (0 slots) slave replicates c4a38513a633aab450a3d491c30ec6b305b7abef[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 查看集群信息1234567891011121314151617181920[root@pseudo-cluster redis-cluster-test]# ./redis-3.2.13/bin/redis-cli -c -p 7000127.0.0.1:7000&gt; CLUSTER NODES963dd0cac7581f29464624cb0df8a678cdfc54cd 192.168.91.146:7002 master - 0 1564657233357 3 connected 10923-163832755ff19dcb8d00967e66f7d19bf95603fa352dc 192.168.91.146:7005 slave 963dd0cac7581f29464624cb0df8a678cdfc54cd 0 1564657233862 6 connected50925d802a5f1be70521fafea196e8b112c122ca 192.168.91.146:7000 myself,master - 0 0 1 connected 0-5460c4a38513a633aab450a3d491c30ec6b305b7abef 192.168.91.146:7001 master - 0 1564657234365 2 connected 5461-109226f3aa71e0d754d54738d746bd617d31adabd0d3f 192.168.91.146:7003 slave 50925d802a5f1be70521fafea196e8b112c122ca 0 1564657235373 4 connected60cd05e9ed0350bd271fabacf00483bc9a34c2da 192.168.91.146:7004 slave c4a38513a633aab450a3d491c30ec6b305b7abef 0 1564657234868 5 connected127.0.0.1:7000&gt; CLUSTER INFOcluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_sent:207cluster_stats_messages_received:207 集群数据操作12345678910111213141516171819202122232425262728[root@pseudo-cluster redis-cluster-test]# ./redis-3.2.13/bin/redis-cli -c -p 7000127.0.0.1:7000&gt; set foo bar-&gt; Redirected to slot [12182] located at 192.168.91.146:7002OK192.168.91.146:7002&gt; set hello world-&gt; Redirected to slot [866] located at 192.168.91.146:7000OK192.168.91.146:7000&gt; set name sunwukong-&gt; Redirected to slot [5798] located at 192.168.91.146:7001OK192.168.91.146:7001&gt; get foo-&gt; Redirected to slot [12182] located at 192.168.91.146:7002"bar"192.168.91.146:7002&gt; get hello-&gt; Redirected to slot [866] located at 192.168.91.146:7000"world"192.168.91.146:7000&gt; get name-&gt; Redirected to slot [5798] located at 192.168.91.146:7001"sunwukong"192.168.91.146:7001&gt; # 从节点默认不能写入[root@pseudo-cluster redis-cluster-test]# ./redis-3.2.13/bin/redis-cli -c -p 7004127.0.0.1:7004&gt; set key001 value001-&gt; Redirected to slot [12657] located at 192.168.91.146:7002OK192.168.91.146:7002&gt; get key001"value001"192.168.91.146:7002&gt; 参考：redis-cluster-test，wytcluster-tutorial，redis.cn]]></content>
      <categories>
        <category>缓存</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>Redis</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAP定理]]></title>
    <url>%2F2019%2F07%2F24%2FCAP%E5%AE%9A%E7%90%86%2F</url>
    <content type="text"><![CDATA[基本内容 Consistency: all nodes see the same data at the same time. 即所有的节点在同一时刻读到同样的数据。 Availability: a guarantee that every request receives a response about whether it was successful or failed. 请求无论成功还是失败，都能收到一个响应。 Partition-Tolerance: the system continues to operate despite arbitrary message loss or failure of part of the system. 系统仍能运行尽管部分节点出问题或者丢失消息 CAP选择分布式系统中不能同时满足C、A、P CA，加强一致性&amp;可用性，放弃分区容忍性，例如传统单机数据库; AP，加强可用性&amp;分区容忍性，放弃强一致性，例如大多数NoSQL系统; CP，加强一致性&amp;分区容忍性，可用性比较差，例如Zookeeper; 如果ZooKeeper集群中出现了网络分割的故障（注：由于交换机故障导致交换机底下的子网间不能互访）；那么ZooKeeper会将它们都从自己管理范围中剔除出去，外界就不能访问到这些节点了，即便这些节点本身是“健康”的，可以正常提供服务的；所以导致到达这些节点的请求被丢失了。 BASE理论在分布式系统中，一般选择加强可用性和分区容忍性而牺牲一致性。 Basically Available：基本可用，允许分区失败； Soft state：软状态，接受一段时间的状态不同步； Eventually consistent：最终一致，保证最终的数据状态是一致的。 在没有发生故障的前提下，数据达到一致状态的时间延迟，取决于网络延迟，系统负载和数据复制方案设计等因素。 More info: 系统架构设计理论与原则、负载均衡及高可用系统设计速记]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>CAP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible Playbook安装docker]]></title>
    <url>%2F2019%2F07%2F11%2FAnsible%20Playbook%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[展示一个安装docker示例，Ansible playbook内容如下： 123456789101112131415161718192021222324---- hosts: all tasks: - name: Remove docker yum: name: ['docker', 'docker-client', 'docker-client-latest', 'docker-common', 'docker-latest', 'docker-latest-logrotate', 'docker-logrotate', 'docker-selinux', 'docker-engine-selinux'] state: removed - name: Install yum utils yum: name: ['yum-utils', 'device-mapper-persistent-data', 'lvm2'] state: installed - name: Set aliyun repo shell: yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo;yum makecache fast - name: Install docker-ce yum: name=docker-ce state=installed - name: Registry mirrors script: ./registry_mirrors.sh - name: After registry mirrors shell: systemctl daemon-reload;systemctl restart docker;systemctl enable docker - name: Show docker version command: docker -v register: result - name: Debug info debug: msg='&#123;&#123;result.stdout_lines&#125;&#125;' registry_mirrors.sh脚本内容 12345678#!/usr/bin/env bashmkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": ["https://kc0hk0ee.mirror.aliyuncs.com"]&#125;EOF 执行 1ansible-playbook install_docker.yml More info: Docker install]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>playbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下ssh公钥认证]]></title>
    <url>%2F2019%2F07%2F01%2FLinux%E4%B8%8Bssh%E5%85%AC%E9%92%A5%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[编号 机器名 IP 1 ansible-manager 192.168.91.140 2 cluster_001 192.168.91.141 … … … 创建密钥对在ansible-manager上执行ssh-keygen命令，一路回车。 12345678910111213141516171819202122232425262728[root@ansible-manager .ssh]# ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:PQtPisFEFbco9jI1loIXyK7y/xr9n6vp562aQ/OkJJs root@ansible-managerThe key's randomart image is:+---[RSA 2048]----+| . .o.o.. || oo . + . || .. * * . || .= * o || . = S + ||. . ..=+=.o || o . o*.=o || . .E.oooo || .oo..BB*o. |+----[SHA256]-----+# 生成密钥对id_rsa &amp; id_rsa.pub，其中id_rsa.pub是公钥。[root@ansible-manager .ssh]# ls -lhtotal 8.0K-rw-------. 1 root root 1.7K Jul 2 03:25 id_rsa-rw-r--r--. 1 root root 402 Jul 2 03:25 id_rsa.pub-rw-r--r--. 1 root root 0 Jul 2 03:24 known_hosts 发送公钥将ansible-manager公钥发送给cluster_001，第一次发送公钥的时候，需要输入密码。 1234567891011121314[root@ansible-manager .ssh]# ssh-copy-id -i ./id_rsa.pub "root@192.168.91.141"/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "./id_rsa.pub"The authenticity of host '192.168.91.141 (192.168.91.141)' can't be established.ECDSA key fingerprint is SHA256:HcrnywII1gZEW3uk2muw+V+JyD0tbedR8hbdvWNrFMM.ECDSA key fingerprint is MD5:55:76:c1:5a:f5:ec:f6:3d:74:e7:d3:ec:ab:49:80:4d.Are you sure you want to continue connecting (yes/no)? yes/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.91.141's password: Number of key(s) added: 1Now try logging into the machine, with: "ssh 'root@192.168.91.141'"and check to make sure that only the key(s) you wanted were added. 测试检查被管理机器cluster_001/root/.ssh/authorized_keys中，写入了ansible-manager 公钥内容。ansible-manager使用ssh连接cluster_001: 1234[root@ansible-manager .ssh]# ssh 192.168.91.141Last login: Tue Jul 2 03:39:14 2019 from 192.168.91.140[root@cluster_001 ~]# hostnamecluster_001 总结 管理机上创建ssh密钥对； 将管理机公钥分发给被管理机； 实现互免认证，可在另一台机器上执行上述流程。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境下的Elasticsearch参数调整]]></title>
    <url>%2F2019%2F06%2F28%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84Elasticsearch%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4%2F</url>
    <content type="text"><![CDATA[开启config/elasticsearch.yml中network.host配置后，ES启动时会切换为生产模式，开发模式下的警告会升级为异常，导致ES节点无法启动。 禁止swapping设置Elasticsearch可锁定的、不被交换出的内存不受限制。编辑config/elasticsearch.yml12# 设置为truebootstrap.memory_lock: true 编辑/etc/security/limits.conf文件，追加下述配置：12# elasticsearch用户锁定内存(不会被swap)不受限制elasticsearch - memlock unlimited 增大文件描述符编辑/etc/security/limits.conf文件，追加下述配置：12# elasticsearch用户最多打开文件描述符的数量elasticsearch - nofile 65536 保证足够的线程数编辑/etc/security/limits.conf文件，追加下述配置：12# 设置elasticsearch用户最多创建线程数elasticsearch - nproc 4096 保证足够的虚拟内存编辑/etc/sysctl.conf文件，追加下述配置：1vm.max_map_count=262144 使设置生效123456789101112131415161718192021222324252627# 加载系统配置参数[root@elasticstack-server filebeat-6.6.2-nginx]# sysctl -p[root@elasticstack-server filebeat-6.6.2-nginx]# sysctl vm.max_map_countvm.max_map_count = 262144# 切换到elasticsearch用户使ulimit设置生效[root@elasticstack-server filebeat-6.6.2-nginx]# su elasticsearch[elasticsearch@elasticstack-server elasticsearch-6.6.2]$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 31140max locked memory (kbytes, -l) unlimitedmax memory size (kbytes, -m) unlimitedopen files (-n) 65536pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 4096virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited# 启动Elasticsearch[elasticsearch@elasticstack-server elasticsearch-6.6.2]$ ./bin/elasticsearch -d -p pid 检查设置Elasticsearch启动成功后，检查设置项：123456# 设置成功[root@elasticstack-server ~]# curl -X GET "localhost:9200/_nodes?filter_path=**.mlockall"&#123;"nodes":&#123;"yW_SUaDnS6WED2QPm5y4TA":&#123;"process":&#123;"mlockall":true&#125;&#125;&#125;&#125;[root@elasticstack-server ~]# curl -X GET "localhost:9200/_nodes/stats/process?filter_path=**.max_file_descriptors"&#123;"nodes":&#123;"yW_SUaDnS6WED2QPm5y4TA":&#123;"process":&#123;"max_file_descriptors":65536&#125;&#125;&#125;&#125; https://www.elastic.co/guide/en/elasticsearch/reference/6.2/system-config.html]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker swarm删除节点]]></title>
    <url>%2F2019%2F05%2F15%2FDocker%20swarm%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[Docker swarm删除节点1234567891011# 在管理节点上先排空节点docker node update --availability drain yyxh5zbei71kq7c5tadoq19ri# 移除节点docker node rm yyxh5zbei71kq7c5tadoq19ri# 或者强制删除docker node rm --force yyxh5zbei71kq7c5tadoq19ri# 在所要删除的节点上执行docker swarm leave# 或强制离开docker swarm leave --force]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络IO之同步、异步 & 阻塞、非阻塞]]></title>
    <url>%2F2019%2F03%2F08%2F%E7%BD%91%E7%BB%9CIO%E4%B9%8B%E5%90%8C%E6%AD%A5%E3%80%81%E5%BC%82%E6%AD%A5%20%26%20%E9%98%BB%E5%A1%9E%E3%80%81%E9%9D%9E%E9%98%BB%E5%A1%9E%2F</url>
    <content type="text"><![CDATA[同步(Synchronous) A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; (同步I/O操作导致请求进程被阻塞，直到I/O操作完成) 异步(Asynchronous) An asynchronous I/O operation does not cause the requesting process to be blocked; (异步I/O操作不会阻塞请求进程) 注意Non-blocking IO在执行recvfrom这个系统调用的时候，如果kernel的数据没有准备好，不会block进程；如果kernel数据准备好了，recvfrom会将数据从内核空间拷贝到用户空间，在这段时间内，进程还是被block的。 阻塞(Blocking) 阻塞调用是指调用结果返回之前，当前线程会被挂起。 非阻塞(Non-blocking) 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 http://www.rowkey.me/blog/2016/01/18/io-model/https://baiweiblog.wordpress.com/tag/non-blocking/https://www.zhihu.com/question/19732473/answer/20851256https://blog.csdn.net/historyasamirror/article/details/5778378]]></content>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git版本回退]]></title>
    <url>%2F2019%2F03%2F04%2FGit%E7%89%88%E6%9C%AC%E5%9B%9E%E9%80%80%2F</url>
    <content type="text"><![CDATA[改动未提交至远程仓库的情况 12# 将HEAD指向commit_id[root@localhost ~]# git reset --hard commit_id 改动已提交至远程仓库的情况 123# revert是放弃指定提交的修改，会生成一次新的提交，需要填写注释，历史记录都在；而reset是指将HEAD指针指到指定提交;[root@localhost ~]# git revert HEAD[root@localhost ~]# git push origin master https://segmentfault.com/q/1010000000140446https://blog.csdn.net/yxlshk/article/details/79944535https://www.cnblogs.com/iloveyou-sky/p/6534409.html]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm节点维护标签]]></title>
    <url>%2F2018%2F10%2F30%2FDocker%20Swarm%E8%8A%82%E7%82%B9%E7%BB%B4%E6%8A%A4%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[Swarm节点维护标签1234567891011121314151617181920212223242526[root@docker_001 ~]# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONlw72u2jd7xi1xagw94cmd86kk * docker_001 Ready Active Leader 18.06.1-ce2igmbyfampcduad32ustl00y8 docker_003 Ready Active 18.06.1-cewudald9nltt9mq9jo9aau3tvf docker_005 Ready Active 18.06.1-ce# 增加一个type=dop的标签[root@docker_001 ~]# docker node update --label-add type=dop lw72u2jd7xi1xagw94cmd86kklw72u2jd7xi1xagw94cmd86kk# 查看标签[root@docker_001 ~]# docker node inspect lw72u2jd7xi1xagw94cmd86kk --prettyID: lw72u2jd7xi1xagw94cmd86kkLabels: - type=dopHostname: docker_001Joined at: 2018-10-24 13:52:32.919572847 +0000 utc...# 移除标签[root@docker_001 ~]# docker node update --label-rm type lw72u2jd7xi1xagw94cmd86kklw72u2jd7xi1xagw94cmd86kk[root@docker_001 ~]# docker node inspect lw72u2jd7xi1xagw94cmd86kk --prettyID: lw72u2jd7xi1xagw94cmd86kkHostname: docker_001Joined at: 2018-10-24 13:52:32.919572847 +0000 utc Add-or-remove-label-metadata]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deploy a stack to a swarm]]></title>
    <url>%2F2018%2F10%2F30%2FDeploy%20a%20stack%20to%20a%20swarm%2F</url>
    <content type="text"><![CDATA[Deploy a stack to a swarm]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Powershell会话中设置环境变量]]></title>
    <url>%2F2018%2F10%2F30%2FPowershell%E4%BC%9A%E8%AF%9D%E4%B8%AD%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[Powershell会话中设置环境变量12345678910111213PS C:\personal\idea\cloud-cook&gt; ls env:DOCKER_HOSTName Value---- -----DOCKER_HOST tcp://192.168.1.114:2375PS C:\personal\idea\cloud-cook&gt; $env:DOCKER_HOST="tcp://192.168.21.129:2375" # 在当前会话中创建DOCKER_HOST环境变量PS C:\personal\idea\cloud-cook&gt; ls env:DOCKER_HOSTName Value---- -----DOCKER_HOST tcp://192.168.21.129:2375 More info: Powershell环境变量]]></content>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm 一、 概述]]></title>
    <url>%2F2018%2F10%2F26%2FDocker%20Swarm%20%E4%B8%80%E3%80%81%20%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[自docker engine 1.12引入swarm模式后，可由一个或多个docker引擎组成一个集群，称之为swarm，一个swarm由一个或多个节点组成。 关键概念节点swarm节点分为两种类型：manager和worker， Manager节点维护集群状态，调度服务，提供swarm模式下的API服务等，多个Manager节点只有一个leader执行编排任务； Worker节点接收并执行从Manager节点分派的任务，默认情况下Manager节点同时也是Worker节点； 服务服务是对在管理节点和工作节点执行任务的定义，创建服务时可以指定具体使用的镜像和容器中执行的命令等。 服务有两种模式:replicated 和 global 任务负载均衡Swarm mode overviewSwarm mode key concepts]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker install]]></title>
    <url>%2F2018%2F10%2F25%2FDocker%20install%2F</url>
    <content type="text"><![CDATA[Uninstall old versions12345678910[root@docker_007 ~]# yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine Install Docker CEInstall required packages123[root@docker_007 ~]# yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 Use the following command to set up the stable repository12345# 注意设置阿里云repo[root@docker_007 ~]# yum-config-manager \ --add-repo \ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo[root@docker_007 ~]# yum makecache fast Install Docker CE123[root@docker_007 ~]# yum install docker-ce[root@docker_007 ~]# docker -vDocker version 18.06.1-ce, build e68fc7a 安装指定版本123456789101112131415161718192021222324252627[root@dlink-72 docker]# yum list docker-ce --showduplicates | sort -rRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast * updates: mirrors.huaweicloud.comLoading mirror speeds from cached hostfileLoaded plugins: fastestmirrorInstalled Packages * extras: mirror.jdcloud.comdocker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable docker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.1.ce-3.el7 @docker-ce-stabledocker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.12.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.12.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.09.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.09.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.06.2.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.06.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.06.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.3.ce-1.el7 docker-ce-stable docker-ce.x86_64 17.03.2.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable * base: mirrors.tuna.tsinghua.edu.cnAvailable Packages[root@dlink-72 docker]# yum install docker-ce-18.06.1.ce-3.el7 镜像加速器使用阿里云Docker镜像加速器，进入阿里云控制台查看配置。https://cr.console.aliyun.com/cn-hangzhou/mirrors 12345678mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": ["https://xxxxx.mirror.aliyuncs.com"]&#125;EOFsystemctl daemon-reloadsystemctl restart docker Start docker123# 启动docker服务，并保持开机自启动[root@docker_007 ~]# systemctl start docker[root@docker_007 ~]# systemctl enable docker 远程访问参考How do I enable the remote API for dockerd 注意关闭防火墙 123456# 查看防火墙状态firewall-cmd --state# 停止firewallsystemctl stop firewalld.service# 禁止firewall开机启动systemctl disable firewalld.service 查看docker服务日志123[root@docker_007 ~]# journalctl -ru docker.service#可以指定日期范围[root@docker_007 ~]# journalctl -ru docker.service --since="2019-08-25 16:20:00" --until="2019-08-25 16:30:00" 其他组件docker composehttps://docs.docker.com/compose/install/ docker machinehttps://docs.docker.com/machine/install-machine/ Get Docker CE for CentOS]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitflow工作流[转载]]]></title>
    <url>%2F2018%2F10%2F08%2FGitflow%E5%B7%A5%E4%BD%9C%E6%B5%81%5B%E8%BD%AC%E8%BD%BD%5D%2F</url>
    <content type="text"><![CDATA[转载：Gitflow工作流，李鼎 工作方式 历史分支 功能分支 发布分支 维护分支 示例 创建开发分支 小红和小明开始开发新功能 小红完成功能开发 小红开始准备发布 小红完成发布 最终用户发现Bug 下一站 这节介绍的Gitflow工作流借鉴自在nvie的Vincent Driessen。 Gitflow工作流定义了一个围绕项目发布的严格分支模型。虽然比功能分支工作流复杂几分，但提供了用于一个健壮的用于管理大型项目的框架。 Gitflow工作流没有用超出功能分支工作流的概念和命令，而是为不同的分支分配一个很明确的角色，并定义分支之间如何和什么时候进行交互。除了使用功能分支，在做准备、维护和记录发布也使用各自的分支。当然你可以用上功能分支工作流所有的好处：Pull Requests、隔离实验性开发和更高效的协作。 工作方式 Gitflow工作流仍然用中央仓库作为所有开发者的交互中心。和其它的工作流一样，开发者在本地工作并push分支到要中央仓库中。 历史分支相对使用仅有的一个master分支，Gitflow工作流使用2个分支来记录项目的历史。master分支存储了正式发布的历史，而develop分支作为功能的集成分支。这样也方便master分支上的所有提交分配一个版本号。 剩下要说明的问题围绕着这2个分支的区别展开。 功能分支每个新功能位于一个自己的分支，这样可以push到中央仓库以备份和协作。但功能分支不是从master分支上拉出新分支，而是使用develop分支作为父分支。当新功能完成时，合并回develop分支。新功能提交应该从不直接与master分支交互。 注意，从各种含义和目的上来看，功能分支加上develop分支就是功能分支工作流的用法。但Gitflow工作流没有止步于此。 发布分支 一旦develop分支上有了做一次发布（或者说快到了既定的发布日）的足够功能，就从develop分支上fork一个发布分支。新建的分支用于开始发布循环，所以从这个时间点开始之后新的功能不能再加到这个分支上——这个分支只应该做Bug修复、文档生成和其它面向发布任务。一旦对外发布的工作都完成了，发布分支合并到master分支并分配一个版本号打好Tag。另外，这些从新建发布分支以来的做的修改要合并回develop分支。 使用一个用于发布准备的专门分支，使得一个团队可以在完善当前的发布版本的同时，另一个团队可以继续开发下个版本的功能。这也打造定义良好的开发阶段（比如，可以很轻松地说，『这周我们要做准备发布版本4.0』，并且在仓库的目录结构中可以实际看到）。 常用的分支约定： 123用于新建发布分支的分支: develop用于合并的分支: master分支命名: release-* 或 release/* 维护分支 维护分支或说是热修复（hotfix）分支用于生成快速给产品发布版本（production releases）打补丁，这是唯一可以直接从master分支fork出来的分支。修复完成，修改应该马上合并回master分支和develop分支（当前的发布分支），master分支应该用新的版本号打好Tag。 为Bug修复使用专门分支，让团队可以处理掉问题而不用打断其它工作或是等待下一个发布循环。你可以把维护分支想成是一个直接在master分支上处理的临时发布。 示例 下面的示例演示本工作流如何用于管理单个发布循环。假设你已经创建了一个中央仓库。 创建开发分支 第一步为master分支配套一个develop分支。简单来做可以本地创建一个空的develop分支，push到服务器上： 12git branch developgit push -u origin develop 以后这个分支将会包含了项目的全部历史，而master分支将只包含了部分历史。其它开发者这时应该克隆中央仓库，建好develop分支的跟踪分支： 123456git clone ssh://user@host/path/to/repo.gitgit checkout -b develop origin/develop#【译注】当没有本地分支 develop 时，# 最后一条命令，我使用更简单的 git checkout develop# 会自动 把 远程分支origin/develop 检出成 本地分支 develop 现在每个开发都有了这些历史分支的本地拷贝。 小红和小明开始开发新功能 这个示例中，小红和小明开始各自的功能开发。他们需要为各自的功能创建相应的分支。新分支不是基于master分支，而是应该基于develop分支： 1git checkout -b some-feature develop 他们用老套路添加提交到各自功能分支上：编辑、暂存、提交：123git statusgit add &lt;some-file&gt;git commit 小红完成功能开发 添加了提交后，小红觉得她的功能OK了。如果团队使用Pull Requests，这时候可以发起一个用于合并到develop分支。否则她可以直接合并到她本地的develop分支后push到中央仓库： 123456789101112# 拉取远程的develop分支，并且当前分支（本地分支some-feature）合并上远程分支developgit pull origin developgit checkout develop# 本地分支some-feature合并上develop#【注意】这个分支已经有远程的develop修改了，所以本地develop无需再做远程拉取的操作git merge some-featuregit push# 删除本地分支git branch -d some-feature#【译注】上面的命令注释为译者添加，以方便理解# 更多说明参见 Issue #18 第一条命令在合并功能前确保develop分支是最新的。注意，功能决不应该直接合并到master分支。冲突解决方法和集中式工作流一样。 小红开始准备发布 这个时候小明正在实现他的功能，小红开始准备她的第一个项目正式发布。像功能开发一样，她用一个新的分支来做发布准备。这一步也确定了发布的版本号： 1git checkout -b release-0.1 develop 这个分支是清理发布、执行所有测试、更新文档和其它为下个发布做准备操作的地方，像是一个专门用于改善发布的功能分支。 只要小红创建这个分支并push到中央仓库，这个发布就是功能冻结的。任何不在develop分支中的新功能都推到下个发布循环中。 小红完成发布 一旦准备好了对外发布，小红合并修改到master分支和develop分支上，删除发布分支。合并回develop分支很重要，因为在发布分支中已经提交的更新需要在后面的新功能中也要是可用的。另外，如果小红的团队要求Code Review，这是一个发起Pull Request的理想时机。 1234567git checkout mastergit merge release-0.1git pushgit checkout developgit merge release-0.1git pushgit branch -d release-0.1 发布分支是作为功能开发（develop分支）和对外发布（master分支）间的缓冲。只要有合并到master分支，就应该打好Tag以方便跟踪。 12git tag -a 0.1 -m "Initial public release" mastergit push --tags Git有提供各种勾子（hook），即仓库有事件发生时触发执行的脚本。可以配置一个勾子，在你push中央仓库的master分支时，自动构建好对外发布。 最终用户发现Bug 对外发布后，小红回去和小明一起做下个发布的新功能开发，直到有最终用户开了一个Ticket抱怨当前版本的一个Bug。为了处理Bug，小红（或小明）从master分支上拉出了一个维护分支，提交修改以解决问题，然后直接合并回master分支： 12345git checkout -b issue-#001 master# Fix the buggit checkout mastergit merge issue-#001git push 就像发布分支，维护分支中新加这些重要修改需要包含到develop分支中，所以小红要执行一个合并操作。然后就可以安全地删除这个分支了： 1234git checkout developgit merge issue-#001git pushgit branch -d issue-#001 下一站 到了这里，但愿你对集中式工作流、功能分支工作流和Gitflow工作流已经感觉很舒适了。你应该也牢固的掌握了本地仓库的潜能，push/pull模式和Git健壮的分支和合并模型。 记住，这里演示的工作流只是可能用法的例子，而不是在实际工作中使用Git不可违逆的条例。所以不要畏惧按自己需要对工作流的用法做取舍。不变的目标就是让Git为你所用。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Jenkins杂记]]></title>
    <url>%2F2018%2F10%2F08%2FJenkins%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Jenkinsadmin初始密码12[root@kvm000 .jenkins]# cat /root/.jenkins/secrets/initialAdminPassword 1342c187dcfcdbf8a1c38dd21b773d95]]></content>
  </entry>
  <entry>
    <title><![CDATA[Item1,考虑使用静态工厂方法替代构造器]]></title>
    <url>%2F2018%2F10%2F07%2FItem1%2C%E8%80%83%E8%99%91%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%9B%BF%E4%BB%A3%E6%9E%84%E9%80%A0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[简述客户端可以通过类提供的公共构造方法获取类实例，除此之外，还可以使用静态工厂方法。 123public static Boolean valueOf(boolean b) &#123; return b ? Boolean.TRUE : Boolean.FALSE;&#125; 好处拥有名称使用静态工厂方法替代构造器，不同于构造方法名称固定，可自定义见名知义的方法名，相对于不同参数签名的多个构造方法设计，更加优雅。 不创建新对象使用静态工厂方法替代构造器，不像构造方法，每次在被调用的时候，都需要new一个实例。 返回子类型使用静态工厂方法替代构造器，不像构造方法，它们可以返回其返回类型的任何子类型的对象。例如，Java Collections Framework 的接口有45个实用程序实现，提供不可修改的集合，同步集合等。几乎所有这些实现都是通过静态工厂方法在一个不可实例化的类java.util.Collections中获取的。 12345public static &lt;T&gt; List&lt;T&gt; unmodifiableList(List&lt;? extends T&gt; list) &#123; return (list instanceof RandomAccess ? new UnmodifiableRandomAccessList&lt;&gt;(list) : new UnmodifiableList&lt;&gt;(list));&#125; 返回对象可变化A fourth advantage of static factories is that the class of the returned object can vary from call to call as a function of the input parameters. 12345678910111213141516171819/** * Creates an empty enum set with the specified element type. * * @param &lt;E&gt; The class of the elements in the set * @param elementType the class object of the element type for this enum * set * @return An empty enum set of the specified type. * @throws NullPointerException if &lt;tt&gt;elementType&lt;/tt&gt; is null */public static &lt;E extends Enum&lt;E&gt;&gt; EnumSet&lt;E&gt; noneOf(Class&lt;E&gt; elementType) &#123; Enum&lt;?&gt;[] universe = getUniverse(elementType); if (universe == null) throw new ClassCastException(elementType + " not an enum"); if (universe.length &lt;= 64) return new RegularEnumSet&lt;&gt;(elementType, universe); else return new JumboEnumSet&lt;&gt;(elementType, universe);&#125; 返回对象不需要存在A fifth advantage of static factories is that the class of the returned object need not exist when the class containing the method is written 服务提供程序框架java.util.ServiceLoader 缺点不能subclassed仅提供静态工厂方法的主要限制是，由于类没有public或protected的构造方法(一般不提供公开构造方法，不绝对，例如Boolean)，因此不能子类化。 123456789class A &#123; private A(B b) &#123; //... &#125; public static A of(B b) &#123; return new A(b); &#125;&#125; 不利于查询使用静态工厂方法的第二个主要的缺点是，程序员查找起来比较困难。这些方法没有在API文档中突出，因此很难弄清楚如何实例化一个提供静态工厂方法而不是构造函数的类。以下是静态工厂方法的一些常用名称。 from—A type-conversion method that takes a single parameter and returns a corresponding instance of this type, for example: Date d = Date.from(instant); of—An aggregation method that takes multiple parameters and returns an in-stance of this type that incorporates them, for example: Set faceCards = EnumSet.of(JACK, QUEEN, KING); • valueOf—A more verbose alternative to from and of, for example: BigInteger prime = BigInteger.valueOf(Integer.MAX_VALUE); instance or getInstance—Returns an instance that is described by its pa-rameters (if any) but cannot be said to have the same value, for example: StackWalker luke = StackWalker.getInstance(options); create or newInstance—Like instance or getInstance, except that the method guarantees that each call returns a new instance, for example: Object newArray = Array.newInstance(classObject, arrayLen); getType—Like getInstance, but used if the factory method is in a different class. Type is the type of object returned by the factory method, for example: FileStore fs = Files.getFileStore(path); newType—Like newInstance, but used if the factory method is in a different class. Type is the type of object returned by the factory method, for example: BufferedReader br = Files.newBufferedReader(path); • type—A concise alternative to getType and newType, for example: List litany = Collections.list(legacyLitany); In summary, static factory methods and public constructors both have their uses, and it pays to understand their relative merits. Often static factories are preferable, so avoid the reflex to provide public constructors without first consid-ering static factories. 参考：Effective Java Third Edition，Joshua bloch]]></content>
  </entry>
  <entry>
    <title><![CDATA[Git命令最佳实践]]></title>
    <url>%2F2018%2F10%2F05%2FGit%E5%91%BD%E4%BB%A4%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Create a repositoryFrom scratch – create a new local repository 1$ git init [project_name] Download form an existing repository 1$ git clone my_url Observe your repositoryList new or modified files not yet committed 1$ git status Show the changes to files not yet staged 1$ git diff Show the changes to staged files 1$ git diff --cached Show all staged and unstaged file changes 1$ git diff HEAD Show the changes between two commit ids 1$ git diff commit1 commit2 List the change dates and authors for a file 1$ git blame [file] Show the file changes for a commit id and/or file 1$ git show [commit_id]:[file] Show full change history 1$ git log show change history for file/directory including diffs 1$ git log -p [file/directory] Working with branchesList all local branches 1$ git branch List all branches, local and remote1$ git branch -av Switch to a branch, and update working directory 1$ git checkout my_branch Create a new branch called new_branch 1$ git branch new_branch Delete the branch called my_branch 1$ git branch -d my_branch Merge branch_a into branch_b 12$ git checkout branch_b$ git merge branch_a Tag the current commit1$ git tag my_tag Make a changeStage the file, ready for commit 1$ git add [file] Stage all changed files, ready for commit 1$ git add . Commit all staged files to versioned history 1$ git commit -m "commit message" Commit all your tracked files to versioned history 1$ git commit -am "commit message" Unstages file, keeping the file changes 1$ git reset [file] Revert everything to the last commit 1$ git reset --hard SynchronizeGet the latest changes from origin (no merge) 1$ git fetch Fetch the latest changes from origin and merge 1$ git pull Fetch the latest changes from origin and rebase 1$ git pull --rebase Push local chages to the origin 1$ git push FinallyWhen in doubt, use git help 1$ git command --help Or visit https://training.github.com/ for official GitHub training. 参考：Git Commands and Best Practices Cheat Sheet，Simon Maple]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL备忘录]]></title>
    <url>%2F2018%2F10%2F05%2FSQL%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[参考：SQL cheat sheet，Oleg Shelajev]]></content>
  </entry>
  <entry>
    <title><![CDATA[java内置性能监控命令]]></title>
    <url>%2F2018%2F10%2F05%2Fjava%E5%86%85%E7%BD%AE%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[jps, JVM Process Status Tooljps, JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程 1234[root@kvm000 bin]# java -versionjava version "1.8.0_181"Java(TM) SE Runtime Environment (build 1.8.0_181-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode) 12345[root@kvm000 bin]# jps -l2368 org.logstash.Logstash19013 jenkins.war9210 sun.tools.jps.Jps2124 org.elasticsearch.bootstrap.Elasticsearch jstat, JVM Statistics Monitoring Tooljstat, JVM Statistics Monitoring Tool, 用于收集HotSpot虚拟机各方面的运行数据 123[root@kvm000 bin]# jstat -gcutil 2124 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 26.74 68.99 67.13 92.88 84.44 3661 22.944 14 0.200 23.143 E、O、M分别是新生代,老年代,元数据区已用占总大小的百分比S0、S1表示两个幸存者区YGC = Young GC, YGCT = Young GC Time 妙计FGC = Full GC, FGCT = Full GC Time 妙计GCT, 总的GC 时间. jinfo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778[root@kvm000 bin]# jinfo 2124Attaching to process ID 2124, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.181-b13Java System Properties:jna.platform.library.path = /usr/lib64:/lib64:/usr/lib:/lib:/usr/lib64/mysqljava.runtime.name = Java(TM) SE Runtime Environmentsun.boot.library.path = /usr/local/jdk1.8.0_181/jre/lib/amd64java.vm.version = 25.181-b13es.path.home = /opt/elk/elasticsearch-6.2.3log4j.shutdownHookEnabled = falsejava.vm.vendor = Oracle Corporationjava.vendor.url = http://java.oracle.com/path.separator = :jna.loaded = truefile.encoding.pkg = sun.iojava.vm.name = Java HotSpot(TM) 64-Bit Server VMsun.java.launcher = SUN_STANDARDuser.country = USsun.os.patch.level = unknownjna.nosys = truejava.vm.specification.name = Java Virtual Machine Specificationuser.dir = /opt/elk/elasticsearch-6.2.3java.runtime.version = 1.8.0_181-b13java.awt.graphicsenv = sun.awt.X11GraphicsEnvironmentjava.endorsed.dirs = /usr/local/jdk1.8.0_181/jre/lib/endorsedos.arch = amd64java.io.tmpdir = /tmp/elasticsearch.WqG997rLline.separator = java.vm.specification.vendor = Oracle Corporationos.name = Linuxio.netty.noKeySetOptimization = truesun.jnu.encoding = UTF-8jnidispatch.path = /tmp/elasticsearch.WqG997rL/jna--1985354563/jna2966756306267189304.tmpjava.library.path = /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/libsun.nio.ch.bugLevel = es.logs.cluster_name = elasticsearchjava.specification.name = Java Platform API Specificationjava.class.version = 52.0sun.management.compiler = HotSpot 64-Bit Tiered Compilersos.version = 3.10.0-862.el7.x86_64user.home = /home/elasticsearchuser.timezone = Asia/Shanghaijava.awt.printerjob = sun.print.PSPrinterJobfile.encoding = UTF-8java.specification.version = 1.8io.netty.recycler.maxCapacityPerThread = 0user.name = elasticsearches.logs.base_path = /opt/elk/elasticsearch-6.2.3/logsjava.class.path = /opt/elk/elasticsearch-6.2.3/lib/elasticsearch-6.2.3.jar:/opt/elk/elasticsearch-6.2.3/lib/elasticsearch-core-6.2.3.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-core-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-analyzers-common-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-backward-codecs-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-grouping-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-highlighter-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-join-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-memory-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-misc-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-queries-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-queryparser-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-sandbox-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-spatial-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-spatial-extras-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-spatial3d-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/lucene-suggest-7.2.1.jar:/opt/elk/elasticsearch-6.2.3/lib/securesm-1.2.jar:/opt/elk/elasticsearch-6.2.3/lib/hppc-0.7.1.jar:/opt/elk/elasticsearch-6.2.3/lib/joda-time-2.9.9.jar:/opt/elk/elasticsearch-6.2.3/lib/snakeyaml-1.17.jar:/opt/elk/elasticsearch-6.2.3/lib/jackson-core-2.8.10.jar:/opt/elk/elasticsearch-6.2.3/lib/jackson-dataformat-smile-2.8.10.jar:/opt/elk/elasticsearch-6.2.3/lib/jackson-dataformat-yaml-2.8.10.jar:/opt/elk/elasticsearch-6.2.3/lib/jackson-dataformat-cbor-2.8.10.jar:/opt/elk/elasticsearch-6.2.3/lib/t-digest-3.0.jar:/opt/elk/elasticsearch-6.2.3/lib/HdrHistogram-2.1.9.jar:/opt/elk/elasticsearch-6.2.3/lib/spatial4j-0.6.jar:/opt/elk/elasticsearch-6.2.3/lib/jts-1.13.jar:/opt/elk/elasticsearch-6.2.3/lib/log4j-api-2.9.1.jar:/opt/elk/elasticsearch-6.2.3/lib/log4j-core-2.9.1.jar:/opt/elk/elasticsearch-6.2.3/lib/log4j-1.2-api-2.9.1.jar:/opt/elk/elasticsearch-6.2.3/lib/jna-4.5.1.jar:/opt/elk/elasticsearch-6.2.3/lib/elasticsearch-cli-6.2.3.jar:/opt/elk/elasticsearch-6.2.3/lib/jopt-simple-5.0.2.jar:/opt/elk/elasticsearch-6.2.3/lib/plugin-classloader-6.2.3.jar:/opt/elk/elasticsearch-6.2.3/lib/elasticsearch-launchers-6.2.3.jar:/opt/elk/elasticsearch-6.2.3/lib/plugin-cli-6.2.3.jares.path.conf = /opt/elk/elasticsearch-6.2.3/configjava.vm.specification.version = 1.8sun.arch.data.model = 64java.home = /usr/local/jdk1.8.0_181/jresun.java.command = org.elasticsearch.bootstrap.Elasticsearch -duser.language = enjava.specification.vendor = Oracle Corporationio.netty.noUnsafe = trueawt.toolkit = sun.awt.X11.XToolkitjava.vm.info = mixed modejava.version = 1.8.0_181java.ext.dirs = /usr/local/jdk1.8.0_181/jre/lib/ext:/usr/java/packages/lib/extsun.boot.class.path = /usr/local/jdk1.8.0_181/jre/lib/resources.jar:/usr/local/jdk1.8.0_181/jre/lib/rt.jar:/usr/local/jdk1.8.0_181/jre/lib/sunrsasign.jar:/usr/local/jdk1.8.0_181/jre/lib/jsse.jar:/usr/local/jdk1.8.0_181/jre/lib/jce.jar:/usr/local/jdk1.8.0_181/jre/lib/charsets.jar:/usr/local/jdk1.8.0_181/jre/lib/jfr.jar:/usr/local/jdk1.8.0_181/jre/classesjava.vendor = Oracle Corporationjava.awt.headless = truefile.separator = /java.vendor.url.bug = http://bugreport.sun.com/bugreport/sun.io.unicode.encoding = UnicodeLittlesun.cpu.endian = littlelog4j2.disable.jmx = truesun.cpu.isalist = VM Flags:Non-default VM flags: -XX:+AlwaysPreTouch -XX:CICompilerCount=3 -XX:CMSInitiatingOccupancyFraction=75 -XX:GCLogFileSize=67108864 -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=348913664 -XX:MaxTenuringThreshold=6 -XX:MinHeapDeltaBytes=196608 -XX:NewSize=348913664 -XX:NumberOfGCLogFiles=32 -XX:OldPLABSize=16 -XX:OldSize=724828160 -XX:-OmitStackTraceInFastThrow -XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintTenuringDistribution -XX:ThreadStackSize=1024 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseFastUnorderedTimeStamps -XX:+UseGCLogFileRotation -XX:+UseParNewGC Command line: -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.io.tmpdir=/tmp/elasticsearch.WqG997rL -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -Xloggc:logs/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=32 -XX:GCLogFileSize=64m -Des.path.home=/opt/elk/elasticsearch-6.2.3 -Des.path.conf=/opt/elk/elasticsearch-6.2.3/config jstat, JVM Statistics Monitoring Tool1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@kvm000 bin]# jstat -gcutil 2124 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 26.74 68.99 67.13 92.88 84.44 3661 22.944 14 0.200 23.143 ### jmap[root@kvm000 bin]# jmap -heap 2124Attaching to process ID 2124, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.181-b13using parallel threads in the new generation. #新生代采用的是并行线程处理方式using thread-local object allocation.Concurrent Mark-Sweep GC #同步并行垃圾回收Heap Configuration: MinHeapFreeRatio = 40 #最小堆使用比例 MaxHeapFreeRatio = 70 #最大堆可用比例 MaxHeapSize = 1073741824 (1024.0MB) #最大堆空间大小 NewSize = 348913664 (332.75MB) #新生代分配大小 MaxNewSize = 348913664 (332.75MB) #最大可新生代分配大小 OldSize = 724828160 (691.25MB) #老生代大小 NewRatio = 2 #新生代比例 SurvivorRatio = 8 #新生代与suvivor的比例 MetaspaceSize = 21807104 (20.796875MB) #元数据区大小 CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB)Heap Usage:New Generation (Eden + 1 Survivor Space): capacity = 314048512 (299.5MB) used = 207005464 (197.4157943725586MB) free = 107043048 (102.0842056274414MB) 65.91512332973576% usedEden Space: capacity = 279183360 (266.25MB) used = 197681056 (188.52334594726562MB) free = 81502304 (77.72665405273438MB) 70.80689049662558% usedFrom Space: capacity = 34865152 (33.25MB) used = 9324408 (8.892448425292969MB) free = 25540744 (24.35755157470703MB) 26.744205790354794% usedTo Space: capacity = 34865152 (33.25MB) used = 0 (0.0MB) free = 34865152 (33.25MB) 0.0% usedconcurrent mark-sweep generation: capacity = 724828160 (691.25MB) used = 486547784 (464.0081253051758MB) free = 238280376 (227.24187469482422MB) 67.125949411237% used19955 interned Strings occupying 2899368 bytes. 12# dump jvmjmap -dump:format=b,file=181005.bin &lt;pid&gt; jhat, JVM Heap Dump Browser用于分析heapdump 文件，它会建立一个HTTP/HTML服务器，让用户在浏览器上查看分析结果 jstack, Stack Trace for Java, 显示虚拟机的线程快找.https://docs.oracle.com/javase/8/docs/technotes/tools/unix/index.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[并发请求数]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%B9%B6%E5%8F%91%E8%AF%B7%E6%B1%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[并发请求数windows server1netstat -ano | findstr "8080" | FIND /v "" /c linux server1netstat -apn | grep :80 | grep -v LISTEN | wc -l]]></content>
  </entry>
  <entry>
    <title><![CDATA[删除Git所有标签]]></title>
    <url>%2F2018%2F10%2F04%2F%E5%88%A0%E9%99%A4%E6%89%80%E6%9C%89Git%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[xargs命令12345[root@localhost ~]# echo "-lh" | cat-lh[root@localhost ~]# echo "-lh" | xargs lstotal 4.0K-rw-------. 1 root root 1.5K Nov 14 2017 anaconda-ks.cfg Remove all git tags1234567891011#Delete local tags.git tag -l | xargs git tag -d#Fetch remote tags.git fetch#Delete remote tags.git tag -l | xargs -n 1 git push --delete origin#Delete local tasg.git tag -l | xargs git tag -d]]></content>
  </entry>
  <entry>
    <title><![CDATA[Gitlab项目初始化]]></title>
    <url>%2F2018%2F10%2F04%2FGitlab%E9%A1%B9%E7%9B%AE%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[命令行指令Git 全局设置12git config --global user.name "wangyt"git config --global user.email "wangyt4dev@gmail.com" 创建新版本库123456git clone git@192.168.1.204:wangyt/test001.gitcd test001touch README.mdgit add README.mdgit commit -m "add README"git push -u origin master 已存在的文件夹123456cd existing_foldergit initgit remote add origin git@192.168.1.204:wangyt/test001.gitgit add .git commit -m "Initial commit"git push -u origin master 已存在的 Git 版本库1234cd existing_repogit remote add origin git@192.168.1.204:wangyt/test001.gitgit push -u origin --allgit push -u origin --tags]]></content>
  </entry>
  <entry>
    <title><![CDATA[Docker入门及基本操作命令]]></title>
    <url>%2F2018%2F07%2F14%2FDocker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[安装参考 Docker install 镜像搜索/下载/查看/删除12# 搜索镜像$ docker search redis 12# 下载镜像$ docker pull redis 12# 查看本地镜像列表$ docker images 12# 删除指定镜像$ docker rmi image-id 容器实例化容器12345# 创建一个新的容器并启动$ docker run --name container-name -d image-name# 例如，创建一个redis容器，并启动$ docker run --name redis-ctnr -d redis 端口映射123# docker容器中程序使用的端口，在容器外无法直接访问，需要将其映射出来# 将redis默认端口，映射出来，使其外部可访问$ docker run -d -p 6379:6379 --name redis-ctnr2 redis 容器列表12345# 查看运行的容器列表$ docker ps# 查看运行和停止的容器列表$ docker ps -a 启动和停止容器1234567891011# 停止一个容器$ docker stop container-name/container-id# 例如，停止redis$ docker stop redis-ctnr# 启动一个容器$ docker start container-name/container-id# 启动 redis$ docker start redis-ctnr 容器删除12345678# 删除指定容器$ docker rm container-id# 删除$ docker rm redis-ctnr# 删除所有容器$ docker rm $(docker ps -a -q) 容器日志12345# 查看当前容器日志$ docker logs container-name/container-id# 查看redis日志$ docker logs redis-ctnr2 登录容器运行中的容器其实就是一个linux系统，我们可以登录进容器 123456# 登录容器$ docker exec -it container-name/container-id bash$ docker exec -it redis-ctnr2 bash# 使用exit退出登录 示例12# 实例化一个RabbitMQ容器$ docker run -d -p 5672:5672 -p 15672:15672 rabbitmq:3-management Dockerfile写一个SpringBoot示例项目1234567891011121314151617181920package github.wyt;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@SpringBootApplication@RestControllerpublic class DockerFileApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DockerFileApplication.class, args); &#125; @RequestMapping("/") public String home() &#123; return "Hello docker!"; &#125;&#125; 打完包后，上传到/tmp/df目录下： 123456[root@localhost df]# pwd/tmp/df[root@localhost df]# ls -lhtotal 14M-rw-r--r--. 1 root root 134 Jul 15 17:44 Dockerfile-rw-r--r--. 1 root root 14M Jul 15 17:37 dockerfile-demo-1.0-SNAPSHOT.jar 创建一个Dockerfile文件，内容如下： 123456789FROM java:8 # 基镜像MAINTAINER wangyongtao # 维护者ADD dockerfile-demo-1.0-SNAPSHOT.jar app.jar # 添加到镜像中并且重命名EXPOSE 8080 # 将容器的8080端口暴露出来，容器外可做端口映射ENTRYPOINT ["java","-jar","/app.jar"] #容器启动时运行 java -jar app.jar 编译镜像 1234567891011121314151617181920212223242526272829303132[root@localhost df]# docker build -t wyt/dockerfile-demo .Sending build context to Docker daemon 14.57 MBStep 1 : FROM java:8Trying to pull repository docker.io/library/java ... 8: Pulling from docker.io/library/javafce5728aad85: Pull complete 76610ec20bf5: Pull complete 60170fec2151: Pull complete e98f73de8f0d: Pull complete 11f7af24ed9c: Pull complete 49e2d6393f32: Pull complete bb9cdec9c7f3: Pull complete Digest: sha256:c1ff613e8ba25833d2e1940da0940c3824f03f802c449f3d1815a66b7f8c0e9d ---&gt; d23bdf5b1b1bStep 2 : MAINTAINER wangyongtao ---&gt; Running in 12ebd4a0fd57 ---&gt; 046529d38bd4Removing intermediate container 12ebd4a0fd57Step 3 : ADD dockerfile-demo-1.0-SNAPSHOT.jar app.jar ---&gt; 7aec1880832eRemoving intermediate container 8712af5da6f3Step 4 : EXPOSE 8080 ---&gt; Running in 1f0127445cf1 ---&gt; 9129fa1cc69bRemoving intermediate container 1f0127445cf1Step 5 : ENTRYPOINT java -jar /app.jar ---&gt; Running in 19e258a38a53 ---&gt; 916933260f9eRemoving intermediate container 19e258a38a53Successfully built 916933260f9e 编译时也可以带着Tag 1[root@localhost df]# docker build -t wyt/dockerfile-demo:0.0.1 . 查看编译好的镜像 1234[root@localhost df]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEwyt/dockerfile-demo 0.0.1 916933260f9e 30 minutes ago 657.7 MBwyt/dockerfile-demo latest 916933260f9e 30 minutes ago 657.7 MB 从镜像实例化容器并启动 1[root@localhost df]# docker run --name docker-demo2 -p 8080:8080 -d wyt/dockerfile-demo 最后使用docker所在系统ip和8080端口即可访问应用 123[root@localhost df]# curl http://192.168.91.146:8080Hello docker![root@localhost df]#]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解lambda表达式]]></title>
    <url>%2F2018%2F03%2F05%2F%E7%90%86%E8%A7%A3lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Lambda表达式是Java 8中的新特性，是Java迈入函数式编程的第一步，它不依赖于任何类而被创建，它能像对象一样被传递和按需执行。 Lambda与单方法接口函数式编程常被用于实现事件监听器，事件监听器在java中常被定义为一个接口，该接口通常只有一个方法： 123public interface StateChangeListener &#123; public void onStateChange(State oldState, State newState);&#125; 这个接口定义了一个方法，期望状态发生改变时被调用。 Java 7中，必须实现此接口才能监听状态更改。假设有一个类StateOwner，它能注册状态事件监听器： 12345public class StateOwner &#123; public void addStateListener(StateChangeListener listener) &#123; // Add state listener... &#125;&#125; Java 7中，可以使用匿名类实现接口添加事件监听器： 1234567StateOwner stateOwner = new StateOwner();stateOwner.addStateListener(new StateChangeListener() &#123; public void onStateChange(State oldState, State newState) &#123; System.out.println("State changed"); &#125;&#125;); 而在Java 8中，可直接使用lambda表达式添加事件监听器： 12345StateOwner stateOwner = new StateOwner();stateOwner.addStateListener( (oldState, newState) -&gt; System.out.println("State changed")); 下面一行就是lambda表达式: 1(oldState, newState) -&gt; System.out.println("State changed") lambda表达式与addStateListener()方法参数的参数类型相匹配，如果lambda表达式与参数类型相匹配(本例中为StateChangeListener)，那么lambda表达式将转换为实现与该参数相同的接口的函数。 Java lambda表达式只能用于与之匹配的类型为单一方法的接口。在上面的例子中，lambda表达式被用作类型为StateChangeListener的方法的参数。StateChangeListener只有一个方法，因此lambda表达式与该接口成功匹配。 Lambda与接口之间的匹配单一方法接口有时候也被称之为函数接口。函数接口匹配lambda分为以下几步： 确保接口只有一个方法lambda表达式参数匹配函数接口方法参数lambda返回值类型匹配函数接口方法返回值类型 Lambda表达式类型推导Java 8之前匿名实现也需要指定具体的接口： 12345stateOwner.addStateListener(new StateChangeListener() &#123; public void onStateChange(State oldState, State newState) &#123; // do something with the old and new state. &#125;&#125;); 下面使用lambda表达式，未提及StateChangeListener接口，但是编译器可根据addStateListener方法声明推断出参数类型： 123stateOwner.addStateListener( (oldState, newState) -&gt; System.out.println("State changed")); lambda表达式中的参数类型也可以类型推导，例如(oldState, newState)可通过onStateChange()的方法声明推导而出。 Lambda表达式参数Java lambda表达式实际上类似于方法，因此lambda表达式可以像方法一样使用参数。 前面显示的lambda表达式的(oldState, newState)部分指定了lambda表达式所需的参数。这些参数必须与单个方法接口上方法的参数相匹配。在这种情况下，这些参数必须与StateChangeListener接口的onStateChange()方法的参数匹配： 1public void onStateChange(State oldState, State newState); 至少lambda表达式和方法中的参数数量必须匹配。其次，如果在lambda表达式中指定了任何参数类型，则这些类型也必须匹配。(类型放入lambda表达式参数，本文稍后会介绍) 无参数方法无参数，可以写成这样： 1() -&gt; System.out.println("Zero parameter lambda"); 一个参数方法一个参数： 1(param) -&gt; System.out.println("One parameter: " + param); 一个参数的时候，亦可以省略圆括号： 1param -&gt; System.out.println("One parameter: " + param); 多个参数1(p1, p2) -&gt; System.out.println("Multiple parameters: " + p1 + ", " + p2); 参数类型如果编译器无法从lambda匹配的函数接口方法中推断出参数类型，那么为lambda表达式指定参数类型有时可能是必需的，这种情况下编译器会提示。Lambda表达式指定参数类型： 1(Car car) -&gt; System.out.println("The car is: " + car.getName()); 如你所见，明确为car指定类型Car。 Lambda函数体Lambda表达式body在 “-&gt;” 右侧被指定，即类似于方法体：1(oldState, newState) -&gt; System.out.println("State changed") 如果需要多行，使用{}括起来： 1234(oldState, newState) -&gt; &#123; System.out.println("Old state: " + oldState); System.out.println("New state: " + newState); &#125; Lambda返回值Lambda表达式也可以有返回值，使用return语句即可： 1234(param) -&gt; &#123; System.out.println("param: " + param); return "return value"; &#125; 简短的形式： 1(a1, a2) -&gt; &#123; return a1 &gt; a2; &#125; 等价于: 1(a1, a2) -&gt; a1 &gt; a2; 用作对象A Java lambda expression is essentially an object. You can assign a lambda expression to a variable and pass it around, like you do with any other object. Here is an example: 123public interface MyComparator &#123; public boolean compare(int a1, int a2);&#125; 123MyComparator myComparator = (a, b) -&gt; a &gt; b;boolean result = myComparator.compare(2, 5); 第一个代码块显示了lambda表达式实现的接口。 第二个代码块显示了lambda表达式的定义，lambda表达式如何分配给变量，最后是如何通过调用它实现的接口方法来调用lambda表达式。 集合示例12345678910111213141516171819202122// 迭代ListList&lt;String&gt; items = new ArrayList&lt;&gt;();items.add("A");items.add("B");items.add("C");items.forEach( item -&gt; &#123; System.out.println(item); &#125;);// 迭代MapMap&lt;String, Integer&gt; maps = new HashMap&lt;&gt;();maps.put("sunwukong", 80);maps.put("zhubajie", 59);maps.put("shaseng", 62);maps.put("tangseng", 87);maps.forEach( (key, value) -&gt; &#123; System.out.println(key + ", " + value); &#125;); 扩展阅读，Java8 lambda表达式10个示例 参考：Java Lambda Expressions，Jakob Jenkov]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解cron表达式]]></title>
    <url>%2F2018%2F03%2F01%2F%E7%90%86%E8%A7%A3cron%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[A Cron Expressionscron表达式形如 0 0 12 * * ? ，由 Seconds Minutes Hours Day of month Month Day of week Year 字段构成，即几秒 几分 几时 几号 几月 周几 哪年。 字段之间使用空格分隔，每个字段可包含任意多个合法的字符。 Table A-1 Cron Expressions Allowed Fields and Values Name Required Allowed Values Allowed Special Characters Seconds Y 0-59 , - * / Minutes Y 0-59 , - * / Hours Y 0-23 , - * / Day of month Y 1-31 , - * ? / L W Month Y 1-12 or JAN-DEC , - * / Day of week Y 1-7 or SUN-SAT , - * ? / L # Year N empty or 1970-2099 , - * / Special Characters* (“all values”) - 用于表示字段中的所有值。例如，Minutes字段中的“*”意味着每一分钟。 ? (“no specific value”) - 不指定特定的值，举个例子，如果我希望我的任务在某月中特定的某天（如第10天）被触发，并且我不关心是星期几被触发，那么我会设置day-of-month字段为10，设置day-of-week字段为? - - 用于指定范围.如hour值为10-12 表示10时，11时，12时。 , - 用于指定附加的值。例如，day-of-week的值为MON,WED,FRI表示星期天，星期三，星期五 / - 用于指定增长。例如，秒字段值为“0/15”表示具体为第0秒，15秒，30秒，45秒的集合，即从第0秒开始，间隔15秒累加。秒字段值为“5/15”表示具体为第5秒，20秒，35秒，50秒的集合，即从第5秒开始，间隔15秒累加。也可以把/写在’’(即空串，没有’’)后面如’/15’,这种情况等价于’0/15’。day-of-month等于1/3 表示从某月的第一天开始，每隔3天触发。 L (“last”) - 指最后，不同的情况有不同的含义，如day-of-month等于“L”表示月中的最后一天。day-of-week等于“L”仅表示7或者SAT。day-of-week等于“6L”表示月中的最后一个周五。也可以从月中的最后一天指定一个偏移量，例如day-of-month等于“L-3”表示月中的倒数第三天。当使用“L”选项时，切记不要指定列表或值的范围，因为可能会得到令人困惑意外的结果。 W (“weekday”) - 用于指定离指定日最近的工作日（星期一至星期五）。例如，如果您要将“15W”指定为day-of-month字段的值，则含义为：“距离本月15日最近的工作日”。因此，如果15日是星期六，触发器将于14日星期五触发。如果15日是星期天，触发器将在16日星期一触发。如果15日是星期二，那么它将在15日星期二触发。 但是，如果您将“1W”指定为day-of-month的值，并且1号是星期六，则触发器将在星期一即3号触发，因为它不能跨越当前月的边界。’W’字符只能在day-of-month是单日而不是日期范围或日期列表时指定。 L和W字符也能联合使用在day-of-mouth字段中，即LW，它表示月中的最后一个工作日。 # - 用于指定月中的第几天。例如，day-of-week等于“6#3”表示月中的第三个星期五。又如，“2#1” 表示月中的第一个星期一，“4#5”表示月中的第五个星期三。注意如果你指定了“#5”，并且该月的星期不存在5个，则该月不会发生任何触发。 合法字符串、月份名称、星期名称不区分大小写，MON等价于mon。 Examples下面的例子自己理解一下吧~1234567891011121314151617181920212223242526272829303132333435363738# Fire at 12:00 PM (noon) every day0 0 12 * * ?# Fire at 10:15 AM every day0 15 10 ? * * # Fire at 10:15 AM every day0 15 10 * * ?# Fire at 10:15 AM every day0 15 10 * * ? * # Fire at 10:15 AM every day during the year 20050 15 10 * * ? 2005 # Fire every minute starting at 2:00 PM and ending at 2:59 PM, every day0 * 14 * * ? # Fire every 5 minutes starting at 2:00 PM and ending at 2:55 PM, every day0 0/5 14 * * ? # Fire every 5 minutes starting at 2:00 PM and ending at 2:55 PM, AND fire every 5 minutes starting at 6:00 PM and ending at 6:55 PM, every day0 0/5 14,18 * * ? # Fire every minute starting at 2:00 PM and ending at 2:05 PM, every day0 0-5 14 * * ? # Fire at 2:10 PM and at 2:44 PM every Wednesday in the month of March0 10,44 14 ? 3 WED # Fire at 10:15 AM every Monday, Tuesday, Wednesday, Thursday and Friday0 15 10 ? * MON-FRI # Fire at 10:15 AM on the 15th day of every month0 15 10 15 * ? # Fire at 10:15 AM on the last day of every month0 15 10 L * ? # Fire at 10:15 AM on the last Friday of every month0 15 10 ? * 6L # Fire at 10:15 AM on the last Friday of every month0 15 10 ? * 6L # Fire at 10:15 AM on every last friday of every month during the years 2002, 2003, 2004, and 20050 15 10 ? * 6L 2002-2005 # Fire at 10:15 AM on the third Friday of every month0 15 10 ? * 6#3 # Fire at 12 PM (noon) every 5 days every month, starting on the first day of the month0 0 12 1/5 * ? # Fire every November 11 at 11:11 AM0 11 11 11 11 ? 参考资料：1.Cron Expressions2.Cron Trigger Tutorial]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate5.0快速入门]]></title>
    <url>%2F2017%2F12%2F20%2FHibernate5.0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[参考 Hibernate ORM 5.0 User Guide整理，作为快速入门简明手册。 体系结构概述 如上图所示：java应用利用Hibernate API 来完成 load, store, query等对其领域数据的操作。 作为JPA的提供者，Hibernate实现了JPA规范，JPA接口和Hibernate具体的实现关系如下图所示： SessionFactory (org.hibernate.SessionFactory) Session实例工厂，一个线程安全的，不可变的代表应用领域模型到一个数据库的映射。EntityManagerFactory在JPA中等价于SessionFactory Session (org.hibernate.Session) 一个单线程，短暂的对象，使用PoEAA《Patterns of Enterprise Application Architecture》中的“Unit of Work”概念设计。 Transaction (org.hibernate.Transaction)]]></content>
      <categories>
        <category>Hibernate</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解POJO]]></title>
    <url>%2F2017%2F12%2F14%2F%E7%90%86%E8%A7%A3POJOs%2F</url>
    <content type="text"><![CDATA[POJO表示Plain Old Java Object。它是一个java对象的实例，并且不耦合在各种框架扩展中。 比如，想从JMS中取出消息，你需要编写一个类实现MessageListener接口。 1234567891011121314151617public class ExampleListener implements MessageListener &#123; public void onMessage(Message message) &#123; if (message instanceof TextMessage) &#123; try &#123; System.out.println(((TextMessage) message).getText()); &#125; catch (JMSException ex) &#123; throw new RuntimeException(ex); &#125; &#125; else &#123; throw new IllegalArgumentException("Message must be of type TextMessage"); &#125; &#125;&#125; 这会使你的代码变得不通用，迁移到其他消息中间件实现时会变的困难。如果你的应用使用了大量的监听器， 那么基于以上的情形选择AMQP或其它方案将变得几乎不可能。 基于POJO的实现意味着你的消息处理不需实现具体框架的接口。 12345678@Componentpublic class ExampleListener &#123; @JmsListener(destination = "myDestination") public void processOrder(String message) &#123; System.out.println(message); &#125;&#125; 在这个例子中，你的代码没有直接绑定任何接口。取而代之的是，连接JMS队列的责任被转移到了 注解中，并且注解更容易更新。当前示例中，你可以用@RabbitListener替换@JmsListener。在其他 情形下，基于POJO的实现方案可能不使用任何注解。 这只是一个小例子，它没有对比JMS和Rabbit MQ，而是用以说明代码不绑定接口的意义。通过使用POJO， 你的代码变得更简单。这样有助于更好的测试，灵活性以及应对以后发生改变的情况。 Spring及各种组件始终致力于减少代码和类库之间的耦合。这是依赖注入的首要概念， 即你的服务(指框架组件等)被使用的方式应该是接通应用程序的一部分，而不是服务本身(否则应用和服务发生耦合)。 https://spring.io/understanding/POJO]]></content>
      <categories>
        <category>编程语言</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows下noinstallZIP方式配置MySQL5.7]]></title>
    <url>%2F2017%2F11%2F04%2FWindows%E4%B8%8BnoinstallZIP%E6%96%B9%E5%BC%8F%E9%85%8D%E7%BD%AEMySQL5.7%2F</url>
    <content type="text"><![CDATA[参考: https://dev.mysql.com/doc/refman/5.7/en/windows-install-archive.html 下载MySQLhttps://dev.mysql.com/downloads/mysql/ 选择 Windows (x86, 64-bit), ZIP Archive MySQL Community 5.7 Server requires the Microsoft Visual C++ 2013 Redistributable Package to run on Windows platforms. MySQL 5.7版本需要安装Microsoft Visual C++ 2013 Redistributable Package 下载安装: https://www.microsoft.com/en-us/download/details.aspx?id=40784 解压安装1. 将下载的MySQL压缩包解压如D:\dev_app\DB\mysql-5.7.20-winx64目录下， 将D:\dev_app\DB\mysql-5.7.20-winx64\bin 加入到系统环境变量中 同时创建数据存储目录如：D:\dev_app\DB\mysql-5.7.20-winx64\data 2. 创建配置mysql.ini文件 As of MySQL 5.7.18, my-default.ini is no longer included in or installed by distribution packages. MySQL 5.7.18之后，my-default.ini不在包含在分发包中，我们在D:\dev_app\DB\mysql-5.7.20-winx64目录下自己创建一个my.ini 内容如下: 12345678910111213141516171819202122232425262728293031# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html# *** DO NOT EDIT THIS FILE. It's a template which will be copied to the# *** default location during install, and will be replaced if you# *** upgrade to a newer version of MySQL.[mysqld]# Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M# Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin# These are commonly set, remove the # and set as required.basedir=D:\dev_app\DB\mysql-5.7.20-winx64datadir=D:\\dev_app\\B\\mysql-5.7.20-winx64\\data# port = .....# server_id = .....# Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2M sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 初始化数据目录管理员权限启动CMD, 使用mysqld初始化目录:1C:\Users\Administrator&gt;mysqld --defaults-file=D:\dev_app\DB\mysql-5.7.20-winx64\my.ini --initialize data目录下会生成一个.err扩展名的文件，打开它，里面会记录生成的MySQL临时密码：12017-11-03T11:53:18.008877Z 1 [Note] A temporary password is generated for root@localhost: xd#pZirf&amp;2Gk 执行目录初始化主要完成以下功能： 检查数据目录是否存在 创建mysql数据库及系统表等 初始化系统表空间等 服务器创建’root’@’localhost’ 超级用户帐户和其他保留帐户 其他 启动MySQL12# 可以不带console参数，日志写到文件中，不在屏幕上输出C:\Users\Administrator&gt;mysqld --console 启动成功1234567892017-11-03T12:06:51.583410Z 0 [Note] .\bin\mysqld.exe: ready for connections.Version: '5.7.20' socket: '' port: 3306 MySQL Community Server (GPL)2017-11-03T12:06:51.583410Z 0 [Note] Executing 'SELECT * FROM INFORMATION_SCHEMA.TABLES;' to get a list of tables using the deprecated partition engine. You may use the startup option '--disable-partition-engine-check' to skip this check.2017-11-03T12:06:51.584410Z 0 [Note] Beginning of list of non-natively partitioned tables2017-11-03T12:06:51.602411Z 0 [Note] End of list of non-natively partitioned tables 连接到MySQL123456789101112131415C:\Users\Administrator&gt;mysql -u root -pEnter password: ************Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 3Server version: 5.7.20Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql&gt; 分配一个新的root密码12mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY '123456';Query OK, 0 rows affected (0.00 sec) 将MySQL作为windows服务确保mysql服务停止 1234567891011121314C:\Users\Administrator&gt;mysqladmin -u root -p shutdownEnter password: ******# another termianl...2017-11-04T13:45:23.331094Z 0 [Note] InnoDB: Buffer pool(s) dump completed at 171104 21:45:232017-11-04T13:45:24.331199Z 0 [Note] InnoDB: Shutdown completed; log sequence number 25654052017-11-04T13:45:24.347199Z 0 [Note] InnoDB: Removed temporary tablespace data file: "ibtmp1"2017-11-04T13:45:24.347199Z 0 [Note] Shutting down plugin 'MEMORY'2017-11-04T13:45:24.347199Z 0 [Note] Shutting down plugin 'CSV'2017-11-04T13:45:24.347199Z 0 [Note] Shutting down plugin 'sha256_password'2017-11-04T13:45:24.347199Z 0 [Note] Shutting down plugin 'mysql_native_password'2017-11-04T13:45:24.347199Z 0 [Note] Shutting down plugin 'binlog'2017-11-04T13:45:24.347199Z 0 [Note] mysqld: Shutdown complete 将MySQL Server作为Windows Service自动启动 12C:\Users\Administrator&gt;mysqld --installService successfully installed. 移除MySQL服务1C:\Users\Administrator&gt;mysqld --remove]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security SAML 实现SP]]></title>
    <url>%2F2017%2F10%2F20%2FSpring%20Security%20SAML%20%E5%AE%9E%E7%8E%B0SP%2F</url>
    <content type="text"><![CDATA[Spring Security SAML 实现SP下载 sample applicationhttps://github.com/spring-projects/spring-security-saml 配置IDP metadata修改 /src/main/webapp/WEB-INF/securityContext.xml，告诉系统下载IDP metadata 从给定的url, 超时5s 123456789101112131415&lt;bean id="metadata" class="org.springframework.security.saml.metadata.CachingMetadataManager"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;bean class="org.opensaml.saml2.metadata.provider.HTTPMetadataProvider"&gt; &lt;constructor-arg&gt; &lt;value type="java.lang.String"&gt;http://idp.ssocircle.com/idp-meta.xml&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value type="int"&gt;5000&lt;/value&gt; &lt;/constructor-arg&gt; &lt;property name="parserPool" ref="parserPool"/&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; 配置SP metadata修改 src/main/webapp/WEB-INF/securityContext.xml 123456789&lt;bean id="metadataGeneratorFilter" class="org.springframework.security.saml.metadata.MetadataGeneratorFilter"&gt; &lt;constructor-arg&gt; &lt;bean class="org.springframework.security.saml.metadata.MetadataGenerator"&gt; &lt;property name="entityId" value="urn:test:winchannel:beijing"/&gt; &lt;!-- 文档中是 &lt;property name="signMetadata" value="false"/&gt;,需改为requestSigned --&gt; &lt;property name="requestSigned" value="false"/&gt; &lt;/bean&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; 上传SP metadata到IDP启动项目后,访问http://localhost/spring-security-saml2-sample/saml/metadata下载生成好的 sp metadata，访问 https://idp.ssocircle.com/sso/UI/Login (建议使用IE，其他浏览器有可能注册不成功) 注册一个新账号，Manage Metadata -&gt; Add new Service Provider Enter the FQDN of the ServiceProvider : 输入 entityId urn:test:winchannel:beijing 输入 metadata information。 测试访问 http://localhost/spring-security-saml2-sample/ 即被要求跳转到 https://idp.ssocircle.com/ 认证。 参考: http://docs.spring.io/spring-security-saml/docs/1.0.0.RELEASE/reference/html/chapter-quick-start.html]]></content>
      <categories>
        <category>WEB技术</category>
      </categories>
      <tags>
        <tag>Spring Security</tag>
        <tag>SAML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis安装]]></title>
    <url>%2F2017%2F10%2F16%2FRedis%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装Redis下载安装1234[root@localhost src] wget http://download.redis.io/releases/redis-4.0.2.tar.gz[root@localhost src] tar xzf redis-4.0.2.tar.gz[root@localhost src] cd redis-4.0.2[root@localhost src] make 启动Redis服务12345678910111213141516171819202122232425262728293031[root@localhost src]# pwd/usr/local/src/redis-4.0.1/src[root@localhost src]# ./redis-server 3163:C 12 Jul 04:23:15.614 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo3163:C 12 Jul 04:23:15.614 # Redis version=4.0.1, bits=64, commit=00000000, modified=0, pid=3163, just started3163:C 12 Jul 04:23:15.614 # Warning: no config file specified, using the default config. In order to specify a config file use ./redis-server /path/to/redis.conf3163:M 12 Jul 04:23:15.615 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 4.0.1 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 3163 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 3163:M 12 Jul 04:23:15.616 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.3163:M 12 Jul 04:23:15.616 # Server initialized3163:M 12 Jul 04:23:15.616 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.3163:M 12 Jul 04:23:15.616 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.3163:M 12 Jul 04:23:15.616 * DB loaded from disk: 0.000 seconds3163:M 12 Jul 04:23:15.616 * Ready to accept connections 通过内建的客户端和Redis交互12345[root@localhost src] ./redis-cliredis&gt; set foo barOKredis&gt; get foo"bar" 远程连接配置12345678[root@localhost src]# pwd/usr/local/src/redis-4.0.1/src[root@localhost src]# vim ../redis.conf# 设置密码为123456requirepass 123456[root@localhost src]# ./redis-server ../redis.conf 客户端远程连接1PS E:\dev_app\Redis-x64-3.0.504&gt; .\redis-cli.exe -h 192.168.80.129 -p 6379 -a "123456" Ref: https://redis.io/download]]></content>
      <categories>
        <category>缓存</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[资源导航]]></title>
    <url>%2F2017%2F10%2F15%2F%E8%B5%84%E6%BA%90%E5%AF%BC%E8%88%AA%2F</url>
    <content type="text"><![CDATA[富强 民主 文明 和谐 html&amp;css基础 html&amp;css基础 HTML5 - MDN 十天精通CSS3 jQuery手册 javascript廖雪峰 javascript进阶 javascript入门 redis教程 Python教程 Gitflow工作流 Firefox开发者工具 Docker Practice 跟阿铭学Linux V2 Windows批处理 标准SQL语法 Spring boot&nbsp;&nbsp;Source ElasticSearch Springboot PowerShell在线教程 Java设计模式 spring cloud tests Spring cloud Hibernate 5.0 User Guide 正则表达式 Elasticsearch: 权威指南 Kibana 用户手册]]></content>
      <categories>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle Scott表MySQL 版本]]></title>
    <url>%2F2017%2F10%2F09%2FOracle%20Scott%E8%A1%A8MySQL%20%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Oracle Scott表MySQL 版本表涉及bonus dept emp salgrade几张表，可以作为SQL学习测试的Demo表. 脚本1234567891011121314/*Navicat MySQL Data TransferSource Server : localhostSource Server Version : 50173Source Host : 192.168.91.129:3306Source Database : oracle_scottTarget Server Type : MYSQLTarget Server Version : 50173File Encoding : 65001Date: 2017-10-09 13:29:54*/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for bonus-- ----------------------------DROP TABLE IF EXISTS `bonus`;CREATE TABLE `bonus` ( `ename` varchar(10) COLLATE utf8_unicode_ci DEFAULT NULL, `job` varchar(9) COLLATE utf8_unicode_ci DEFAULT NULL, `sal` decimal(7,2) DEFAULT NULL, `comm` decimal(7,2) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;-- ------------------------------ Records of bonus-- ------------------------------ ------------------------------ Table structure for dept-- ----------------------------DROP TABLE IF EXISTS `dept`;CREATE TABLE `dept` ( `deptno` int(10) unsigned NOT NULL AUTO_INCREMENT, `dname` varchar(15) COLLATE utf8_unicode_ci DEFAULT NULL, `loc` varchar(50) COLLATE utf8_unicode_ci DEFAULT NULL, PRIMARY KEY (`deptno`)) ENGINE=InnoDB AUTO_INCREMENT=41 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;-- ------------------------------ Records of dept-- ----------------------------INSERT INTO `dept` VALUES ('10', 'ACCOUNTING', 'NEW YORK');INSERT INTO `dept` VALUES ('20', 'RESEARCH', 'DALLAS');INSERT INTO `dept` VALUES ('30', 'SALES', 'CHICAGO');INSERT INTO `dept` VALUES ('40', 'OPERATIONS', 'BOSTON');-- ------------------------------ Table structure for emp-- ----------------------------DROP TABLE IF EXISTS `emp`;CREATE TABLE `emp` ( `empno` int(10) unsigned NOT NULL AUTO_INCREMENT, `ename` varchar(15) COLLATE utf8_unicode_ci DEFAULT NULL, `job` varchar(10) COLLATE utf8_unicode_ci DEFAULT NULL, `mgr` int(10) unsigned DEFAULT NULL, `hiredate` date DEFAULT NULL, `sal` decimal(7,2) DEFAULT NULL, `comm` decimal(7,2) DEFAULT NULL, `deptno` int(10) unsigned DEFAULT NULL, PRIMARY KEY (`empno`), KEY `deptno` (`deptno`) USING BTREE, CONSTRAINT `emp_ibfk_1` FOREIGN KEY (`deptno`) REFERENCES `dept` (`deptno`)) ENGINE=InnoDB AUTO_INCREMENT=7935 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;-- ------------------------------ Records of emp-- ----------------------------INSERT INTO `emp` VALUES ('7369', 'SMITH', 'CLERK', '7902', '1980-12-17', '800.00', null, '20');INSERT INTO `emp` VALUES ('7499', 'ALLEN', 'SALESMAN', '7698', '1981-02-20', '1600.00', '300.00', '30');INSERT INTO `emp` VALUES ('7521', 'WARD', 'SALESMAN', '7698', '1981-02-22', '1250.00', '500.00', '30');INSERT INTO `emp` VALUES ('7566', 'JONES', 'MANAGER', '7839', '1981-04-02', '2975.00', null, '20');INSERT INTO `emp` VALUES ('7654', 'MARTIN', 'SALESMAN', '7698', '1981-09-28', '1250.00', '1400.00', '30');INSERT INTO `emp` VALUES ('7698', 'BLAKE', 'MANAGER', '7839', '1981-05-01', '2850.00', null, '30');INSERT INTO `emp` VALUES ('7782', 'CLARK', 'MANAGER', '7839', '1981-06-09', '2450.00', null, '10');INSERT INTO `emp` VALUES ('7788', 'SCOTT', 'ANALYST', '7566', '1987-07-13', '3000.00', null, '20');INSERT INTO `emp` VALUES ('7839', 'KING', 'PRESIDENT', null, '1981-11-17', '5000.00', null, '10');INSERT INTO `emp` VALUES ('7844', 'TURNER', 'SALESMAN', '7698', '1981-09-08', '1500.00', '0.00', '30');INSERT INTO `emp` VALUES ('7876', 'ADAMS', 'CLERK', '7788', '1987-07-13', '1100.00', null, '20');INSERT INTO `emp` VALUES ('7900', 'JAMES', 'CLERK', '7698', '1981-12-03', '950.00', null, '30');INSERT INTO `emp` VALUES ('7902', 'FORD', 'ANALYST', '7566', '1981-12-03', '3000.00', null, '20');INSERT INTO `emp` VALUES ('7934', 'MILLER', 'CLERK', '7782', '1982-01-23', '1300.00', null, '10');-- ------------------------------ Table structure for salgrade-- ----------------------------DROP TABLE IF EXISTS `salgrade`;CREATE TABLE `salgrade` ( `grade` int(10) unsigned DEFAULT NULL, `losal` int(10) unsigned DEFAULT NULL, `hisal` int(10) unsigned DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;-- ------------------------------ Records of salgrade-- ----------------------------INSERT INTO `salgrade` VALUES ('1', '700', '1200');INSERT INTO `salgrade` VALUES ('2', '1201', '1400');INSERT INTO `salgrade` VALUES ('3', '1401', '2000');INSERT INTO `salgrade` VALUES ('4', '2001', '3000');INSERT INTO `salgrade` VALUES ('5', '3001', '9999');]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux安装Mysql]]></title>
    <url>%2F2017%2F08%2F21%2FLinux%E4%B8%8B%E5%AE%89%E8%A3%85Mysql%2F</url>
    <content type="text"><![CDATA[安装Mysql系统信息12345[root@localhost ~]# uname -a Linux localhost.localdomain 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux[root@localhost ~]# cat /etc/issueCentOS release 6.6 (Final)Kernel \r on an \m 查看当前系统是否已经安装Mysql12[root@localhost ~]# yum list installed | grep mysqlmysql.x86_64 5.1.73-8.el6_8 @base 删除自带Mysql1[root@localhost ~]# yum -y remove mysql.x86_64 查看yum库上mysql版本123456[root@localhost ~]# yum list | grep mysqlmysql.x86_64 5.1.73-8.el6_8 @base mysql-devel.x86_64 5.1.73-8.el6_8 @base mysql-libs.x86_64 5.1.73-8.el6_8 @base mysql-server.x86_64 5.1.73-8.el6_8 @base ... yum安装Mysql1[root@localhost ~]# yum -y install mysql-server mysql mysql-devel 查看安装后的Mysql信息12345678910111213141516[root@localhost ~]# rpm -qi mysql-serverName : mysql-server Relocations: (not relocatable)Version : 5.1.73 Vendor: CentOSRelease : 8.el6_8 Build Date: Fri 27 Jan 2017 06:25:43 AM CSTInstall Date: Mon 03 Jul 2017 12:53:49 AM CST Build Host: c1bm.rdu2.centos.orgGroup : Applications/Databases Source RPM: mysql-5.1.73-8.el6_8.src.rpmSize : 25884131 License: GPLv2 with exceptionsSignature : RSA/SHA1, Fri 27 Jan 2017 06:35:28 AM CST, Key ID 0946fca2c105b9dePackager : CentOS BuildSystem &lt;http://bugs.centos.org&gt;URL : http://www.mysql.comSummary : The MySQL server and related filesDescription :MySQL is a multi-user, multi-threaded SQL database server. MySQL is aclient/server implementation consisting of a server daemon (mysqld)and many different client programs and libraries. This package containsthe MySQL server and some accompanying files and directories. 禁用linux防火墙禁用selinux123456789101112[root@localhost ~]# cat /etc/selinux/config# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled # 禁用selinux修改后需要重启# SELINUXTYPE= can take one of these two values:# targeted - Targeted processes are protected,# mls - Multi Level Security protection.SELINUXTYPE=targeted 关闭防火墙暂时关闭1[root@localhost ~]# service iptables stop 永久关闭1[root@localhost ~]# chkconfig iptables off 其他设置####设置Mysql服务开机启动123456789[root@localhost ~]# cat /etc/rc.local #!/bin/sh## This script will be executed *after* all the other init scripts.# You can put your own initialization stuff in here if you don't# want to do the full Sys V style init stuff.touch /var/lock/subsys/localservice mysqld start 查看MySQL脚本信息123456789101112131415161718192021mysql&gt; select version();+-----------+| version() |+-----------+| 5.1.73 |+-----------+1 row in setmysql&gt; SHOW VARIABLES LIKE "%version%";+-------------------------+---------------------+| Variable_name | Value |+-------------------------+---------------------+| protocol_version | 10 || version | 5.1.73 || version_comment | Source distribution || version_compile_machine | x86_64 || version_compile_os | redhat-linux-gnu |+-------------------------+---------------------+5 rows in setmysql&gt;]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nonce与重放攻击]]></title>
    <url>%2F2017%2F07%2F25%2FNonce%E4%B8%8E%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[重放攻击（Replay attack）是一种网络攻击，它恶意的欺诈性的重复或拖延正常的数据传输。 —— [ Wikipedia ] 使用签名认证方式设计的RESTFul API，当请求信息被第三方拦截之后，由于其含有认证信息，当再次发起该请求时，如果没有相应的保护机制，请求会再次通过验证，造成重放攻击的风险。 为避免该问题，通常情况下的做法是： 每次发起HTTP请求，都需要加上timestamp参数，然后把timestamp和其他参数一起进行签名。服务端接收到HTTP请求后，将客户端timestamp与服务端当前时间比较，判断是否超过了请求有效期，比如60s，如果超过了则认为是非法的请求。 如此一来从第一次请求发起的时间算起，60s之后再访问时会被服务端拒绝，但是在60s有效期内，依然可以发起重放攻击。 解决方案： 客户端生成一个随机字符串Nonce (Number used once), 并且参与签名 服务端第一次接收到请求，去缓存中查询Nonce是否存在 如果不存在，则认为在有效期内该请求第一次访问，放行；然后将Nonce保存在缓存中，并设置有效期为60s，60s之后该Nonce缓存失效被清除 如果存在，则认为在有效期内该请求Replay，拒绝提供访问 需要保证的是有效期内并发请求生成随机数的唯一性。]]></content>
      <categories>
        <category>WEB技术</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interview]]></title>
    <url>%2F2017%2F07%2F18%2FInterview%2F</url>
    <content type="text"><![CDATA[推断打印结果12345678910public static void main(String args[]) &#123; String a = "hello2"; final String b = "hello"; String d = "hello"; String c = b + 2; String e = d + 2; System.out.println((a == c)); System.out.println((a == e));&#125; 结果：12truefalse 解析：由于b的值确定且被final修饰，会被当做编译期常量使用，即编译期出现b变量的地方会被直接替换，替换后，a和c都指向字符串常量池中的hello2地址，故a==c为true；而String e = d + 2;会被编译器转换为类似于 String e = new StringBuilder(d).append(“2”); 故 a==e为false. 请画出a，b，c，d内存分布图123456public static void main(String args[]) &#123; int[] a = &#123; 1, 2, 3 &#125;; int[] b = &#123; 4, 5, 6 &#125;; int[] c = &#123; 7, 8, 9 &#125;; int[][] d = &#123; a, b, c &#125;;&#125; 解析： 判断输出结果I12345678910111213141516public class Example &#123; String str = new String("Hello"); char[] ch = &#123;'a','b','c'&#125;; public static void main(String[] args) &#123; Example ex = new Example(); ex.change(ex.str, ex.ch); System.out.println(ex.str); System.out.println(ex.ch); &#125; public void change(String str, char[] ch)&#123; str= "Hi"; ch[1]= 'h'; &#125;&#125; 运行结果：12Helloahc 解析： II12345678910111213141516public class Person &#123; public int age; public static void changeEmployee(Person employee) &#123; employee = new Person(); employee.age = 1000; &#125; public static void main(String[] args) &#123; Person employee = new Person(); employee.age = 100; changeEmployee(employee); System.out.println(employee.age); &#125;&#125; 哪些操作是原子性操作1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 1x = 10; 解析：注意y = x，需要读取和赋值，并非原子性操作。 以下代码是否有问题，并解释。12345678910111213141516171819202122232425262728293031public class Example &#123; public static void main(String[] args) &#123; Outputer outputer = new Outputer(); final Thread t0 = new Thread(() -&gt; &#123; outputer.output2("How are you?"); &#125;); final Thread t1 = new Thread(() -&gt; &#123; outputer.output("Fine, thank you."); &#125;); t0.start(); t1.start(); &#125; static class Outputer &#123; public synchronized void output(String name) &#123; int len = name.length(); for (int i = 0; i &lt; len; i++) &#123; System.out.print(name.charAt(i)); &#125; System.out.println(); &#125; public static synchronized void output2(String name) &#123; int len = name.length(); for (int i = 0; i &lt; len; i++) &#123; System.out.print(name.charAt(i)); &#125; System.out.println(); &#125; &#125;&#125; 解析：ouput和output2两个方法分别使用类对象和类实例对象的锁，两个线程不会竞争同一个锁资源，因而不会产生互斥，从而导致输出混乱。 SQL查询员工表emp： empno ename job mgr hiredate sal comm deptno 7369 SMITH CLERK 7902 1980-12-17 800.00 NULL 20 7499 ALLEN SALESMAN 7698 1981-02-20 1600.00 300.00 30 7521 WARD SALESMAN 7698 1981-02-22 1250.00 500.00 30 7566 JONES MANAGER 7839 1981-04-02 2975.00 NULL 20 7654 MARTIN SALESMAN 7698 1981-09-28 1250.00 1400.00 30 7698 BLAKE MANAGER 7839 1981-05-01 2850.00 NULL 30 7782 CLARK MANAGER 7839 1981-06-09 2450.00 NULL 10 7788 SCOTT ANALYST 7566 1987-07-13 3000.00 NULL 20 7839 KING PRESIDENT NULL 1981-11-17 5000.00 NULL 10 7844 TURNER SALESMAN 7698 1981-09-08 1500.00 0.00 30 7876 ADAMS CLERK 7788 1987-07-13 1100.00 NULL 20 7900 JAMES CLERK 7698 1981-12-03 950.00 NULL 30 7902 FORD ANALYST 7566 1981-12-03 3000.00 NULL 20 7934 MILLER CLERK 7782 1982-01-23 1300.00 NULL 10 部门表dept： deptno dname loc 10 ACCOUNTING NEW YORK 20 RESEARCH DALLAS 30 SALES CHICAGO 40 OPERATIONS BOSTON 查询部门表在员工表中不存在的部门号;123456SELECT d.deptnoFROM dept dWHERE NOT EXISTS (SELECT NULLFROM emp eWHERE d.deptno = e.deptno); 查询工资高于部门平均工资的员工;1234567SELECT e2.ename,e2.sal,e2.deptno,r1._avgFROM emp e2INNER JOIN (SELECT e1.deptno, AVG(e1.sal) AS _avgFROM emp e1GROUP BY e1.deptno) r1 ON e2.deptno = r1.deptno AND e2.sal &gt; r1._avgORDER BY e2.deptno ASC, e2.sal DESC; 查询部门工资前三名的员工;1234567SELECT t0.deptno, t0.ename, t0.salFROM emp t0WHERE (SELECT COUNT(1)FROM emp t1WHERE t0.deptno = t1.deptno AND t1.sal &gt;= t0.sal) &lt;= 3ORDER BY deptno,sal DESC; 解析： 员工工资排名前3，可以转换为: 工资大于等于自己的人数(count)小于等于3]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile关键字解析[转载]]]></title>
    <url>%2F2017%2F07%2F16%2Fvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%A7%A3%E6%9E%90%5B%E8%BD%AC%E8%BD%BD%5D%2F</url>
    <content type="text"><![CDATA[volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。 volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。 以下是本文的目录大纲： 一.内存模型的相关概念 二.并发编程中的三个概念 三.Java内存模型 四.深入剖析volatile关键字 五.使用volatile关键字的场景 若有不正之处请多多谅解，并欢迎批评指正。 请尊重作者劳动成果，转载请标明原文链接： http://www.cnblogs.com/dolphin0520/p/3920373.html 内存模型的相关概念大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。 也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。 比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？ 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。 最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法： 1）通过在总线加LOCK#锁的方式 2）通过缓存一致性协议 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 并发编程中的三个概念原子性 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 一个很经典的例子就是银行账户转账问题： 比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。 试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。 所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。 同样地反映到并发编程中会出现什么结果呢？ 举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？i = 9; 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。 那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 可见性123456//线程1执行的代码int i = 0;i = 10; //线程2执行的代码j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 有序性有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：1234int i = 0; boolean flag = false;i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子：1234int a = 10; //语句1int r = 2; //语句2a = a + 3; //语句3r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是： 那么可不可能是这个执行顺序呢： 语句2 语句1 语句4 语句3 不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此时线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 Java内存模型在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句：1i = 10; 执行线程必须先在自己的工作内存中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。 那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？ 原子性 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i： 请分析以下哪些操作是原子性操作：1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 可见性对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性(修饰共享变量的setter or getter)，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 有序性 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 这8条原则摘自《深入理解Java虚拟机》。 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则： 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 深入剖析volatile关键字在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。 volatile关键字的两层语义 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 2）禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行：12345678//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125; //线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 volatile保证原子性吗？ 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子：1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 把上面的代码改成以下任何一种都可以达到效果： 采用synchronized：1234567891011121314151617181920212223public class Test &#123; public int inc = 0; public synchronized void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用Lock：1234567891011121314151617181920212223242526272829public class Test &#123; public int inc = 0; Lock lock = new ReentrantLock(); public void increase() &#123; lock.lock(); try &#123; inc++; &#125; finally&#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用AtomicInteger：1234567891011121314151617181920212223public class Test &#123; public AtomicInteger inc = new AtomicInteger(); public void increase() &#123; inc.getAndIncrement(); &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 volatile能保证有序性吗？ 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子：12345678//x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子：123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 volatile的原理和实现机制前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 使用volatile关键字的场景synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 状态标记量123456789volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125; 12345678910volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); double check1234567891011121314151617class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 至于为何需要这么写请参考： 单例模式与双重检测Java 中的双重检查（Double-Check）]]></content>
      <categories>
        <category>编程语言</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[传统定时器技术]]></title>
    <url>%2F2017%2F07%2F16%2F%E4%BC%A0%E7%BB%9F%E5%AE%9A%E6%97%B6%E5%99%A8%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[传统定时器技术5秒后爆炸,然后每隔3秒爆炸一次123456789101112131415161718192021@Testpublic void testTimer01() &#123; /** * 面向对象的方式思考：一个定时器实例，拥有计划schedule方法，具体的任务由TimerTask实现. */ new Timer().schedule(new TimerTask() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + " !!!bombing!!! "); &#125; &#125;, 5000, 3000); while (true) &#123; System.out.println(Thread.currentThread().getName() + " " + Calendar.getInstance().get(Calendar.SECOND)); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 结果12345678910111213141516main 27main 28main 29main 30main 31Timer-0 !!!bombing!!! main 32main 33main 34Timer-0 !!!bombing!!! main 35main 36main 37Timer-0 !!!bombing!!! main 38main 39]]></content>
      <categories>
        <category>编程语言</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[传统线程技术]]></title>
    <url>%2F2017%2F07%2F16%2F%E4%BC%A0%E7%BB%9F%E7%BA%BF%E7%A8%8B%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[创建并启动一个线程方法一12345678910public static void main(String[] args) &#123; Thread thd01 = new Thread("thd01") &#123; @Override public void run() &#123; System.out.println("the Thread " + Thread.currentThread().getName() + " is executing."); &#125; &#125;; thd01.start(); System.out.println("the Thread " + Thread.currentThread().getName() + " is executing.");&#125; 方法二1234567891011public static void main(String[] args) &#123; Thread thd02 = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("the Thread " + Thread.currentThread().getName() + " is executing."); &#125; &#125;); thd02.setName("thd02"); thd02.start(); System.out.println("the Thread " + Thread.currentThread().getName() + " is executing.");&#125; 判断输出结果12345678910111213public static void main(String[] args) &#123; new Thread(new Runnable() &#123; public void run() &#123; System.out.println("the Thread01 " + Thread.currentThread().getName() + " is executing."); &#125; &#125;) &#123; /** 覆盖了Runnable中定义的方run() */ @Override public void run() &#123; System.out.println("the Thread02 " + Thread.currentThread().getName() + " is executing."); &#125; &#125;.start();&#125;]]></content>
      <categories>
        <category>编程语言</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
</search>
